<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>e392bcaf-f24b-4565-8bbc-256261539a91</title><style type="text/css"> * {margin:0; padding:0; text-indent:0; }
 .s1 { color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 17pt; }
 .s2 { color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
 h2 { color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 12pt; }
 h1 { color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 14pt; }
 h3 { color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 .p, p { color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; margin:0pt; }
 .s3 { color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s4 { color: black; font-family:"Book Antiqua", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s5 { color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s6 { color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: bold; text-decoration: none; font-size: 10pt; }
 .s7 { color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; }
 .s8 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 10pt; }
 .s9 { color: black; font-family:"Eras Medium ITC", sans-serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 6.5pt; vertical-align: 3pt; }
 .s10 { color: black; font-family:"Eras Medium ITC", sans-serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 10pt; }
 .s11 { color: black; font-family:"Eras Medium ITC", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 li {display: block; }
 #l1 {padding-left: 0pt;counter-reset: c1 1; }
 #l1> li>*:first-child:before {counter-increment: c1; content: counter(c1, decimal)" "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 14pt; }
 #l1> li:first-child>*:first-child:before {counter-increment: c1 0;  }
 #l2 {padding-left: 0pt;counter-reset: c2 1; }
 #l2> li>*:first-child:before {counter-increment: c2; content: counter(c2, decimal)". "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l2> li:first-child>*:first-child:before {counter-increment: c2 0;  }
 #l3 {padding-left: 0pt; }
 #l3> li>*:first-child:before {content: "• "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l4 {padding-left: 0pt; }
 #l4> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l5 {padding-left: 0pt; }
 #l5> li>*:first-child:before {content: "• "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l6 {padding-left: 0pt; }
 #l6> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l7 {padding-left: 0pt; }
 #l7> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l8 {padding-left: 0pt; }
 #l8> li>*:first-child:before {content: "* "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: -2pt; }
 #l9 {padding-left: 0pt; }
 #l9> li>*:first-child:before {content: "* "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: -2pt; }
 #l10 {padding-left: 0pt; }
 #l10> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l11 {padding-left: 0pt; }
 #l11> li>*:first-child:before {content: "* "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: -2pt; }
 #l12 {padding-left: 0pt; }
 #l12> li>*:first-child:before {content: "* "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: -2pt; }
 #l13 {padding-left: 0pt; }
 #l13> li>*:first-child:before {content: "· "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l14 {padding-left: 0pt; }
 #l14> li>*:first-child:before {content: "· "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l15 {padding-left: 0pt; }
 #l15> li>*:first-child:before {content: "• "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l16 {padding-left: 0pt; }
 #l16> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l17 {padding-left: 0pt; }
 #l17> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l18 {padding-left: 0pt; }
 #l18> li>*:first-child:before {content: "• "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l19 {padding-left: 0pt; }
 #l19> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l20 {padding-left: 0pt; }
 #l20> li>*:first-child:before {content: "• "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l21 {padding-left: 0pt; }
 #l21> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l22 {padding-left: 0pt; }
 #l22> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l23 {padding-left: 0pt;counter-reset: g1 1; }
 #l23> li>*:first-child:before {counter-increment: g1; content: "("counter(g1, lower-latin)") "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l23> li:first-child>*:first-child:before {counter-increment: g1 0;  }
 #l24 {padding-left: 0pt;counter-reset: c2 1; }
 #l24> li>*:first-child:before {counter-increment: c2; content: counter(c2, decimal)". "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l24> li:first-child>*:first-child:before {counter-increment: c2 0;  }
 #l25 {padding-left: 0pt;counter-reset: h1 1; }
 #l25> li>*:first-child:before {counter-increment: h1; content: "("counter(h1, lower-latin)") "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l25> li:first-child>*:first-child:before {counter-increment: h1 0;  }
 #l26 {padding-left: 0pt; }
 #l26> li>*:first-child:before {content: "• "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l27 {padding-left: 0pt;counter-reset: c2 1; }
 #l27> li>*:first-child:before {counter-increment: c2; content: counter(c2, decimal)". "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l27> li:first-child>*:first-child:before {counter-increment: c2 0;  }
 #l28 {padding-left: 0pt; }
 #l28> li>*:first-child:before {content: "• "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l29 {padding-left: 0pt; }
 #l29> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l30 {padding-left: 0pt; }
 #l30> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l31 {padding-left: 0pt; }
 #l31> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l32 {padding-left: 0pt; }
 #l32> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l33 {padding-left: 0pt; }
 #l33> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l34 {padding-left: 0pt; }
 #l34> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l35 {padding-left: 0pt; }
 #l35> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l36 {padding-left: 0pt; }
 #l36> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l37 {padding-left: 0pt; }
 #l37> li>*:first-child:before {content: "• "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l38 {padding-left: 0pt; }
 #l38> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l39 {padding-left: 0pt; }
 #l39> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l40 {padding-left: 0pt; }
 #l40> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l41 {padding-left: 0pt; }
 #l41> li>*:first-child:before {content: "• "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l42 {padding-left: 0pt; }
 #l42> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l43 {padding-left: 0pt; }
 #l43> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l44 {padding-left: 0pt; }
 #l44> li>*:first-child:before {content: "* "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: -2pt; }
 #l45 {padding-left: 0pt; }
 #l45> li>*:first-child:before {content: "* "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: -2pt; }
 #l46 {padding-left: 0pt; }
 #l46> li>*:first-child:before {content: "· "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l47 {padding-left: 0pt; }
 #l47> li>*:first-child:before {content: "· "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l48 {padding-left: 0pt;counter-reset: c2 1; }
 #l48> li>*:first-child:before {counter-increment: c2; content: counter(c2, decimal)". "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l48> li:first-child>*:first-child:before {counter-increment: c2 0;  }
 #l49 {padding-left: 0pt; }
 #l49> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l50 {padding-left: 0pt; }
 #l50> li>*:first-child:before {content: "* "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: -2pt; }
 #l51 {padding-left: 0pt; }
 #l51> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l52 {padding-left: 0pt; }
 #l52> li>*:first-child:before {content: "* "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: -2pt; }
 li {display: block; }
 #l53 {padding-left: 0pt; }
 #l53> li>*:first-child:before {content: "– "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l54 {padding-left: 0pt; }
 #l54> li>*:first-child:before {content: "* "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: -2pt; }
 #l55 {padding-left: 0pt; }
 #l55> li>*:first-child:before {content: "* "; color: black; font-family:"Book Antiqua", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: -2pt; }
</style></head><body><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="text-indent: 0pt;text-align: center;">Assignment 4</p><p class="s2" style="padding-top: 19pt;text-indent: 0pt;text-align: center;">chadha aouina, mail: chadhausi.ch</p><h2 style="padding-top: 8pt;text-indent: 0pt;text-align: center;">Deadline<span class="s2">: 17 January 2024 - 10.00am</span></h2><p style="padding-top: 11pt;text-indent: 0pt;text-align: left;"><br/></p><h1 style="text-indent: 0pt;text-align: center;">Conversational model with Transformers</h1><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l1"><li data-list-text="1"><h1 style="padding-left: 62pt;text-indent: -21pt;text-align: left;"><a name="bookmark0">&zwnj;</a>Data (40 pts)</h1><p style="text-indent: 0pt;text-align: left;"/><ol id="l2"><li data-list-text="1."><h3 style="padding-top: 9pt;padding-left: 65pt;text-indent: -12pt;text-align: left;">movie lines.txt:</h3><ul id="l3"><li data-list-text="•"><p style="padding-top: 7pt;padding-left: 87pt;text-indent: -10pt;text-align: left;">This file contains the actual lines of dialogue from various movies.</p></li><li data-list-text="•"><p style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: left;">Each line is uniquely identified by a code (e.g., L1045).</p></li><li data-list-text="•"><p style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: left;">The format includes a series of identifiers separated by ”+++$$$+++”:</p><ul id="l4"><li data-list-text="–"><p style="padding-top: 3pt;padding-left: 106pt;text-indent: -9pt;text-align: left;">User ID (e.g., u0, u2)</p></li><li data-list-text="–"><p style="padding-top: 1pt;padding-left: 106pt;text-indent: -9pt;text-align: left;">Movie ID (e.g., m0)</p></li><li data-list-text="–"><p style="padding-top: 1pt;padding-left: 106pt;text-indent: -9pt;text-align: left;">The name of the character speaking the line (e.g., BIANCA, CAMERON)</p></li><li data-list-text="–"><p style="padding-top: 1pt;padding-left: 106pt;text-indent: -9pt;text-align: left;">The dialogue text itself.</p></li></ul></li><li data-list-text="•"><p style="padding-top: 3pt;padding-left: 87pt;text-indent: -11pt;text-align: left;">The structured format delineates these different elements clearly, fa- cilitating parsing and analysis.</p><p style="text-indent: 0pt;text-align: left;"/><h3 style="padding-top: 7pt;padding-left: 65pt;text-indent: 0pt;text-align: left;">movie conversations.txt:</h3><p style="text-indent: 0pt;text-align: left;"/></li><li data-list-text="•"><p style="padding-top: 8pt;padding-left: 87pt;text-indent: -11pt;text-align: left;">This file documents the structure of conversations, referencing the lines from movie lines.txt.</p><p style="text-indent: 0pt;text-align: left;"/></li><li data-list-text="•"><p style="padding-top: 4pt;padding-left: 87pt;text-indent: -11pt;text-align: left;">Each entry starts with user IDs (e.g., u0, u2) and a movie ID (m0), similar to the movie lines.txt format.</p></li><li data-list-text="•"><p style="padding-top: 4pt;padding-left: 87pt;text-indent: -11pt;text-align: left;">Following these identifiers, there’s a list of line codes enclosed in square brackets.</p><p style="text-indent: 0pt;text-align: left;"/></li><li data-list-text="•"><p style="padding-top: 4pt;padding-left: 87pt;text-indent: -11pt;text-align: left;">These codes correspond to the lines in movie lines.txt, indicating the flow of conversation between characters.</p></li></ul></li><li data-list-text="2."><p style="padding-top: 7pt;padding-left: 76pt;text-indent: -23pt;text-align: left;">• <b>Function: </b><span class="s3">create-sentence-pairs</span></p><ul id="l5"><li data-list-text="•"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -11pt;text-align: justify;">Purpose: <span class="p">This function takes the dialogue lines and their correspond- ing conversations from the Cornell Movie Dialogues Corpus and creates pairs of sentences.</span></h3></li><li data-list-text="•"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Implementation:</h3><ul id="l6"><li data-list-text="–"><p style="padding-top: 3pt;padding-left: 106pt;text-indent: -9pt;text-align: justify;">It iterates through each conversation (a list of line IDs).</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="–"><p style="padding-left: 106pt;text-indent: -10pt;text-align: justify;">For each conversation, it pairs sequential lines to form dialogue pairs. This includes creating overlapping pairs for conversa- tions with more than two lines. For instance, in a conversation with four lines (s1, s2, s3, s4), it generates the pairs (s1, s2), (s2, s3), and (s3, s4).</p></li></ul></li><li data-list-text="•"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Commentary on the Choice:</h3><ul id="l7"><li data-list-text="–"><h3 style="padding-top: 3pt;padding-left: 106pt;text-indent: -9pt;text-align: justify;">Advantages:</h3><ul id="l8"><li data-list-text="*"><p class="s4" style="padding-top: 3pt;padding-left: 123pt;text-indent: -8pt;line-height: 80%;text-align: justify;">Richer Contextual Data: <span class="p">The approach offers a more detailed context for each dialogue segment.</span></p></li><li data-list-text="*"><p class="s4" style="padding-top: 2pt;padding-left: 123pt;text-indent: -8pt;line-height: 90%;text-align: justify;">Better Data Utilization: <span class="p">Maximizes the use of available data.</span></p></li><li data-list-text="*"><p class="s4" style="padding-left: 123pt;text-indent: -8pt;line-height: 80%;text-align: justify;">Versatility for Different Applications: <span class="p">Applicable to a variety of use cases in dialogue processing and analysis.</span></p></li></ul></li><li data-list-text="–"><h3 style="padding-top: 2pt;padding-left: 106pt;text-indent: -9pt;text-align: justify;">Potential Concerns:</h3><ul id="l9"><li data-list-text="*"><p class="s4" style="padding-top: 3pt;padding-left: 123pt;text-indent: -8pt;line-height: 80%;text-align: justify;">Data Redundancy: <span class="p">The approach might lead to repetitive data in the dataset.</span></p></li><li data-list-text="*"><p class="s4" style="padding-top: 2pt;padding-left: 123pt;text-indent: -8pt;line-height: 12pt;text-align: justify;">Complex Conversations Handling: <span class="p">In complex dialogues with multiple speakers or non-linear conversation threads, this method may not accurately capture the true conversational dynamics.</span></p></li></ul></li></ul></li></ul></li><li data-list-text="3."><p style="padding-top: 7pt;padding-left: 76pt;text-indent: -23pt;text-align: justify;">• <b>Tokenization Strategy:</b></p><p style="text-indent: 0pt;text-align: left;"/><ul id="l10"><li data-list-text="–"><h3 style="padding-top: 3pt;padding-left: 106pt;text-indent: -9pt;text-align: justify;">Use of clear punctuation Function:</h3><ul id="l11"><li data-list-text="*"><p style="padding-top: 2pt;padding-left: 123pt;text-indent: -8pt;line-height: 87%;text-align: justify;">This function handles punctuation by creating separate to- kens for punctuation symbols (?, ., !) and removing other types of punctuation.</p></li></ul></li><li data-list-text="–"><h3 style="padding-top: 2pt;padding-left: 106pt;text-indent: -9pt;text-align: justify;">Appending Special Tokens:</h3><ul id="l12"><li data-list-text="*"><p style="padding-top: 2pt;padding-left: 123pt;text-indent: -8pt;line-height: 80%;text-align: justify;"><span class="s5">&lt;</span>EOS<span class="s5">&gt;</span>(<i>End Of Sentence</i>): Appended to the end of each sen- tence.</p><ul id="l13"><li data-list-text="·"><p class="s4" style="padding-top: 2pt;padding-left: 133pt;text-indent: -7pt;text-align: justify;">Purpose: <span class="p">Signifies the end of a sentence, crucial in sequence modeling tasks for helping the model to understand sen- tence boundaries.</span></p></li></ul></li><li data-list-text="*"><p style="padding-top: 2pt;padding-left: 123pt;text-indent: -8pt;line-height: 80%;text-align: justify;"><span class="s5">&lt;</span>SOS<span class="s5">&gt;</span>(<i>Start Of Sentence</i>): Appended only at the beginning of each answer.</p><ul id="l14"><li data-list-text="·"><p class="s4" style="padding-top: 2pt;padding-left: 133pt;text-indent: -7pt;text-align: justify;">Purpose: <span class="p">Useful in sequence-to-sequence models, particu- larly in generation tasks like dialogue systems, where it signals the beginning of a response.</span></p></li></ul></li></ul></li></ul><ul id="l15"><li data-list-text="•"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Commentary on Special Tokens (<span class="s6">&lt;</span>SOS<span class="s6">&gt;</span>, <span class="s6">&lt;</span>EOS<span class="s6">&gt;</span>):</h3><ul id="l16"><li data-list-text="–"><p class="s5" style="padding-top: 3pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">&lt;<span class="p">EOS</span>&gt;<span class="p">: Helps the model differentiate sentences and under- stand their limits, especially important in dialogues where mul- tiple sentences might be spoken by one character in a single turn.</span></p></li><li data-list-text="–"><p class="s5" style="padding-top: 1pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">&lt;<span class="p">SOS</span>&gt;<span class="p">: Essential for response generation tasks, providing a clear starting point for generating a response, improving the model’s ability to generate coherent and contextually relevant answers.</span></p><p style="text-indent: 0pt;text-align: left;"/></li></ul></li></ul></li><li data-list-text="4."><p style="padding-top: 7pt;padding-left: 76pt;text-indent: -23pt;text-align: justify;">• <b>Choice of max length:</b></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"/><ul id="l17"><li data-list-text="–"><p style="padding-left: 106pt;text-indent: -10pt;text-align: justify;">The value of <span class="s3">max length </span>was chosen to balance retaining enough data for training while removing overly long sentences that might be outliers or less useful.</p></li><li data-list-text="–"><p style="padding-top: 1pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">Based on the histogram analysis, the vast majority of sentences are short, with a steep drop-off in frequency as sentence length increases. A threshold is considered around the point where the histogram bars become very short.</p></li><li data-list-text="–"><p style="padding-top: 2pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">A threshold of 30 is selected as it is likely to retain a substantial portion of the data, effectively encompassing most of the typical sentence lengths observed in the dataset.</p></li></ul><ul id="l18"><li data-list-text="•"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Filtering Pairs:</h3><p style="text-indent: 0pt;text-align: left;"/><ul id="l19"><li data-list-text="–"><p style="padding-top: 3pt;padding-left: 106pt;text-indent: -10pt;text-align: left;">After deciding on the <span class="s3">max length</span>, pairs where either sentence exceeds this threshold are filtered out.</p></li><li data-list-text="–"><p style="padding-top: 2pt;padding-left: 106pt;text-indent: -10pt;text-align: left;">This step ensures that the training data is more uniform in length, potentially improving the efficiency and performance of the model.</p></li></ul></li></ul><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 68pt;text-indent: 0pt;text-align: left;"><span><table border="0" cellspacing="0" cellpadding="0"><tr><td><img width="371" height="373" src="data:image/jpg;base64,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"/></td></tr></table></span></p><p style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="5."><p style="padding-left: 65pt;text-indent: -12pt;text-align: left;">sentences were saved in pickle format</p></li><li data-list-text="6."><p style="padding-top: 7pt;padding-left: 65pt;text-indent: -12pt;text-align: justify;">The Counter class from the collections module is used to count the oc- currences of each word in the corpus. The filtering step eliminates any sentence pair where at least one word in either sentence is not in the set of common words.</p></li><li data-list-text="7."><p style="padding-top: 7pt;padding-left: 65pt;text-indent: -12pt;text-align: left;">list was saved in pickle</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="8."><p style="padding-left: 65pt;text-indent: -12pt;text-align: left;">To randomly sample a subset of sentences from our corpus, i used Python’s random module, which includes a function called sample for this pur- pose. This function allows us to select a specified number of unique ele- ments from a list.</p><ul id="l20"><li data-list-text="•"><h3 style="padding-top: 7pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Choice: Generating 60,000 sentences for the initial dataset.</h3><ul id="l21"><li data-list-text="–"><p class="s4" style="padding-top: 3pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">Comment: <span class="p">This choice is beneficial for creating a rich and di- verse dataset. A larger initial set offers a broad spectrum of data, which is crucial for training robust models.</span></p></li></ul></li><li data-list-text="•"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Choice: Randomly sampling 10,000 sentences from the larger set.</h3><ul id="l22"><li data-list-text="–"><p class="s4" style="padding-top: 3pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">Comment on Efficiency: <span class="p">Training on a smaller subset reduces com- putational demands and speeds up the training process. This is particularly important when resources are limited or when iter- ative testing and development are required.</span></p></li><li data-list-text="–"><p class="s4" style="padding-top: 2pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">Comment on Reproducibility: <span class="p">The decision to fix a seed before sampling ensures that the experiments can be reproduced.</span></p></li></ul></li></ul></li><li data-list-text="9."><p style="padding-top: 8pt;padding-left: 65pt;text-indent: -12pt;text-align: left;">To complete the Vocabulary class, i filled in the add-word and add-sentence methods. The add-word method should add a new word to the word2index dictionary and update the index2word dictionary. The add-sentence method should split the sentence into words and add each word to the vocabu- lary using the add-word method. n-words: I introduced a new instance variable n-words to keep track of the total number of unique words in the vocabulary. This helps to assign a unique index to each new word. add-word Method: This method now checks if a word is not already in the word2index dictionary. If it’s not, the method adds the word with the next available index and increments n-words. add-sentence Method: This method splits the sentence into words and adds each word to the vocabulary by calling add-word. Dictionary Updates: Both word2index and index2word dictionaries are updated in the add-word method to en- sure they are always synchronized. Initialization of n-words: It’s set to 3</p><p style="padding-left: 65pt;text-indent: 0pt;text-align: justify;">to account for the special tokens that are already in the dictionaries. By making these changes, the Vocabulary class now has the functionality to process sentences and add new words to the vocabulary, while ensuring that each word has a unique index. This is crucial for later converting sentences into tensors of word indices, which can be used as input to machine learning models.</p></li><li data-list-text="10."><p style="padding-top: 8pt;padding-left: 65pt;text-indent: -17pt;text-align: justify;">To modify the Dataset class i implemented the –init–, –len–, and –getitem– methods. Additionally, for efficient batch processing, we need a collate- fn that will pad the sequences in each batch to the same length.</p><ol id="l23"><li data-list-text="(a)"><h3 style="padding-top: 8pt;padding-left: 87pt;text-indent: -16pt;text-align: justify;">–init–<span class="p">: Initializes the Dataset object with a Vocabulary instance and a list of sentence pairs.</span></h3></li><li data-list-text="(b)"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -17pt;text-align: justify;">–len–<span class="p">: Returns the number of pairs in the dataset.</span></h3></li><li data-list-text="(c)"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -16pt;text-align: justify;">–getitem–<span class="p">: Converts a pair of sentences (at the given index ix) into tensors of word indices. It assumes that the sentences have already been tokenized and that each word can be converted into an index using the Vocabulary instance.</span></h3><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="(d)"><p style="padding-left: 87pt;text-indent: -17pt;text-align: justify;"><b>collate-fn</b>: This function is used by the DataLoader to merge a list of samples into a batch. It pads the sequences so that all sequences in a batch have the same length. The padding value is set to the index of <span class="s5">&lt;</span>PAD<span class="s5">&gt;</span>in the vocabulary, which is 0.</p></li><li data-list-text="(e)"><h3 style="padding-top: 4pt;padding-left: 87pt;text-indent: -16pt;text-align: justify;">DataLoader<span class="p">: The DataLoader object is created using the dataset and the custom collate-fn. The batch-size parameter controls how many items are in each batch, and collate-fn is the function that will pad the batches.</span></h3></li></ol><p style="padding-top: 8pt;padding-left: 65pt;text-indent: 0pt;text-align: justify;">When the DataLoader is iterated over, it will provide batches of padded sequences ready to be fed into a model. This setup is essential for batch training since models typically require input tensors to be of the same shape. The collate-fn ensures that despite sentences being of different lengths, they are padded to the maximum length within each batch for uniformity.</p><p style="padding-top: 6pt;text-indent: 0pt;text-align: left;"><br/></p></li></ol></li><li data-list-text="2"><h1 style="padding-left: 62pt;text-indent: -21pt;text-align: left;"><a name="bookmark1">&zwnj;</a>Model &amp; Tools for training (35 pts)</h1><ol id="l24"><li data-list-text="1."><p style="padding-top: 9pt;padding-left: 65pt;text-indent: -12pt;text-align: left;">The PositionalEncoding module integrates sinusoidal encoding for adding sequence information to the Transformer model. Its use of sine and co- sine functions at different frequencies aids the model in learning rela- tive word positions. The implementation scales to handle variable input lengths and incorporates dropout for regularization. Additionally, the assert statement ensures the input sequence length does not exceed the specified maximum length, providing robustness in handling different data inputs.</p></li><li data-list-text="2."><p style="padding-top: 8pt;padding-left: 65pt;text-indent: -12pt;text-align: left;">To complete the TransformerModel class, i implemented the initialization of the various components within the transformer architecture.</p><ol id="l25"><li data-list-text="(a)"><h3 style="padding-top: 10pt;padding-left: 87pt;text-indent: -16pt;text-align: left;">Embedding Layer<span class="p">: Maps token indices to dense vectors of size d- model.</span></h3></li><li data-list-text="(b)"><h3 style="padding-top: 4pt;padding-left: 87pt;text-indent: -17pt;text-align: left;">Positional Encoding<span class="p">: Adds positional context to the input embed- dings.</span></h3></li><li data-list-text="(c)"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -16pt;text-align: left;">Transformer Layer<span class="p">: The core transformer which processes the input.</span></h3></li><li data-list-text="(d)"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -17pt;text-align: justify;">Output Linear Layer<span class="p">: A linear layer that projects from the hidden space back to the vocab size (to generate probabilities for each to- ken).</span></h3></li><li data-list-text="(e)"><h3 style="padding-top: 4pt;padding-left: 87pt;text-indent: -16pt;text-align: justify;">self.embedding<span class="p">: Embedding layer to convert input word indices into embeddings.</span></h3></li><li data-list-text="(f)"><h3 style="padding-top: 4pt;padding-left: 87pt;text-indent: -14pt;text-align: justify;">self.pos-encoder<span class="p">: The positional encoding layer adds information about the sequence position of each token.</span></h3></li><li data-list-text="(g)"><h3 style="padding-top: 4pt;padding-left: 87pt;text-indent: -17pt;text-align: left;">self.transformer<span class="p">: A PyTorch transformer layer, which is set to have batch-first=True to accept input data in the shape (batch-size, sequence- length, features).</span></h3></li><li data-list-text="(h)"><h3 style="padding-top: 4pt;padding-left: 87pt;text-indent: -17pt;text-align: left;">self.linear<span class="p">: A fully connected layer to project the transformer out- puts back into the vocabulary space.</span></h3><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="(i)"><h3 style="padding-left: 87pt;text-indent: -14pt;text-align: left;">self.pad-id<span class="p">: Stored for use when creating padding masks.</span></h3></li><li data-list-text="(j)"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -13pt;text-align: left;">self.vocab-size<span class="p">: Saved for use in the output layer.</span></h3></li><li data-list-text="(k)"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -17pt;text-align: left;">self.init-weights()<span class="p">: A method is called to initialize the weights of the embedding and linear layers.</span></h3></li></ol><p style="padding-top: 10pt;padding-left: 65pt;text-indent: 0pt;text-align: justify;">The init-weights method initializes the weights of the embedding and linear layers with uniform random weights.</p><p style="padding-top: 4pt;padding-left: 65pt;text-indent: 0pt;text-align: justify;">By filling in the <span class="s3">--init-- </span>method with the necessary components, the TransformerModel is now ready to be instantiated and used for training or inference.</p></li><li data-list-text="3."><p style="padding-top: 8pt;padding-left: 65pt;text-indent: -12pt;line-height: 94%;text-align: left;">To complete the create-padding-mask function in the TransformerModel class, i implemented logic that creates a boolean mask for the <span class="s5">&lt;</span>PAD<span class="s5">&gt;</span>tokens. This function should take a tensor as input and return a boolean tensor where the positions of <span class="s5">&lt;</span>PAD<span class="s5">&gt;</span>tokens are marked as True, and all other positions are False. In this function:</p><p style="padding-top: 4pt;padding-left: 65pt;text-indent: 0pt;text-align: justify;">The input x is a tensor containing token indices. The pad-id parame- ter is the index of the <span class="s5">&lt;</span>PAD<span class="s5">&gt;</span>token in the vocabulary, which is 0 by default. The function compares each element in x to pad-id to create a boolean mask. Wherever x equals pad-id, the mask will have True; oth- erwise, it will have False. This mask is then returned and can be used in the transformer model to ignore <span class="s5">&lt;</span>PAD<span class="s5">&gt;</span>tokens during processing. This mask allows the model to disregard padding tokens during attention cal- culations, ensuring that only meaningful tokens contribute to the model’s output.</p></li><li data-list-text="4."><p style="padding-top: 8pt;padding-left: 65pt;text-indent: -12pt;text-align: justify;">To complete the forward function of the TransformerModel class, i in- tegrated all the components i’ve created: embedding layers, positional encoding, transformer layers, and linear layers. In addition, we should correctly apply the padding masks and the future masks. In this forward function:</p><ul id="l26"><li data-list-text="•"><p style="padding-top: 10pt;padding-left: 87pt;text-indent: -11pt;text-align: justify;"><b>Padding Masks</b>: <span class="s3">src-pad-mask </span>and <span class="s3">tgt-pad-mask </span>are created using the create-padding-mask function. These masks ensure that the model does not consider padding tokens during attention calcu- lations in the transformer. They are applied to both the source and target sequences.</p></li><li data-list-text="•"><p style="padding-top: 3pt;padding-left: 87pt;text-indent: -11pt;text-align: justify;"><b>Embedding and Positional Encoding</b>: Both the source (<span class="s3">src</span>) and target (<span class="s3">tgt</span>) sequences are passed through the embedding layer and then the positional encoding layer. This process adds meaningful representation to each token and includes information about the po- sition of each token in the sequence.</p></li><li data-list-text="•"><p style="padding-top: 3pt;padding-left: 87pt;text-indent: -11pt;text-align: justify;"><b>Future Mask for Target Sequence</b>: The <span class="s3">tgt-mask </span>is a future mask created by the generate-square-subsequent-mask method. This mask ensures that during training, the model does not use future tokens in the target sequence for prediction. It masks future positions to en- force the model to only use past and current positions’ information for predictions.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="•"><h3 style="padding-left: 87pt;text-indent: -11pt;text-align: justify;">Transformer Layer<span class="p">: The source and target sequences, along with their respective masks, are passed to the transformer layer. The transformer processes these sequences, applying self-attention and feedforward networks while respecting the masks.</span></h3></li><li data-list-text="•"><h3 style="padding-top: 4pt;padding-left: 87pt;text-indent: -11pt;text-align: justify;">Linear Layer<span class="p">: The output of the transformer layer is then passed through a linear layer that projects the transformer’s output dimen- sions back to the vocabulary size. This step is essential for generat- ing the final predictions or logits.</span></h3></li></ul></li><li data-list-text="5."><p style="padding-top: 10pt;padding-left: 65pt;text-indent: -12pt;text-align: justify;">This choice aligns with PyTorch’s implementation of attention mecha- nisms, where Boolean masks are used for efficiency and clarity. The mask with True values indicates positions to be ignored (like padding in se- quences), and False indicates positions to be considered. During compu- tation, these masks are applied in such a way that the attention weights at positions marked True are set to zero or a very low value (effectively,</p><p style="padding-left: 65pt;text-indent: 0pt;text-align: justify;">-inf when using softmax), ensuring these positions do not contribute to the final output.</p><p style="padding-top: 6pt;text-indent: 0pt;text-align: left;"><br/></p></li></ol></li><li data-list-text="3"><h1 style="padding-left: 62pt;text-indent: -21pt;text-align: left;"><a name="bookmark2">&zwnj;</a>Training (35 pts)</h1><ol id="l27"><li data-list-text="1."><p style="padding-top: 9pt;padding-left: 65pt;text-indent: -12pt;text-align: left;">Training Pipeline Components:</p><ul id="l28"><li data-list-text="•"><h3 style="padding-top: 7pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Data Preparation:</h3><ul id="l29"><li data-list-text="–"><p style="padding-top: 4pt;padding-left: 106pt;text-indent: -10pt;line-height: 93%;text-align: justify;">The input, output, and target sentences are prepared as per the specifications. The input sentence ends with <span class="s5">&lt;</span>EOS<span class="s5">&gt;</span>, the de- coder’s input (output sentence) starts with <span class="s5">&lt;</span>SOS<span class="s5">&gt;</span>and does not include <span class="s5">&lt;</span>EOS<span class="s5">&gt;</span>, and the target sentence (what we want to pre- dict) ends with <span class="s5">&lt;</span>EOS<span class="s5">&gt;</span>and does not include <span class="s5">&lt;</span>SOS<span class="s5">&gt;</span>.</p></li></ul></li><li data-list-text="•"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Model Initialization:</h3><ul id="l30"><li data-list-text="–"><p style="padding-top: 3pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">The Transformer model is initialized with the given hyperpa- rameters.</p></li></ul></li><li data-list-text="•"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Loss Function and Optimizer:</h3><ul id="l31"><li data-list-text="–"><p style="padding-top: 3pt;padding-left: 106pt;text-indent: -9pt;text-align: justify;">The chosen loss function is Cross-Entropy Loss.</p></li><li data-list-text="–"><p style="padding-top: 1pt;padding-left: 106pt;text-indent: -9pt;text-align: justify;">The optimizer could be Adam or a similar advanced optimizer.</p></li></ul></li><li data-list-text="•"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Learning Rate Scheduler:</h3><ul id="l32"><li data-list-text="–"><p style="padding-top: 3pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">The use of a scheduler (e.g., ReduceLROnPlateau, StepLR, or a custom warm-up with decay scheduler) is important for con- trolling the learning rate during training.</p></li></ul></li><li data-list-text="•"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Training Loop:</h3><ul id="l33"><li data-list-text="–"><p style="padding-top: 3pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">The training loop iterates over epochs and batches of data. For each batch, it processes the input through the model, calculates loss, performs backpropagation, and updates model parame- ters.</p></li><li data-list-text="–"><p style="padding-top: 2pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">The loop also handles validation using a separate validation dataset to monitor the model’s performance and prevent over- fitting.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li></ul></li><li data-list-text="•"><h3 style="padding-left: 87pt;text-indent: -10pt;text-align: justify;">Performance Monitoring:</h3><ul id="l34"><li data-list-text="–"><p style="padding-top: 3pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">Tracking training and validation loss helps in understanding the learning progress. The goal is to minimize the validation loss to a threshold (e.g., below 1.5 as mentioned).</p></li></ul></li><li data-list-text="•"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Comments:</h3><ul id="l35"><li data-list-text="–"><p style="padding-top: 3pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">The train function encapsulates the entire training process. The training loop computes the loss for each batch and updates the model parameters. The validation phase evaluates the model performance on unseen data. A learning rate scheduler adjusts the learning rate based on validation loss. Early stopping is implemented to halt training when the target validation loss is achieved. The function plots the training and validation losses for visual analysis.</p></li></ul></li><li data-list-text="•"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Usage:</h3><ul id="l36"><li data-list-text="–"><p style="padding-top: 3pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">This function would be called with the initialized model, data loaders, loss function, optimizer, and scheduler. The function returns the trained model and also visualizes the loss trends.</p><p style="padding-top: 7pt;padding-left: 65pt;text-indent: 0pt;text-align: left;">please run the code to see plot it will look like this (loss didnt reach 1.5)</p><p style="padding-left: 65pt;text-indent: 0pt;text-align: left;"><span><table border="0" cellspacing="0" cellpadding="0"><tr><td><img width="379" height="380" src="data:image/jpg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAF8AXsDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD9Uc0Zo/lXkfxQ8e+I/h/4m1i8gura80mLwdqmr22mPb7St3aNb4LS5yVfz8YwMbc85oA6D4kf8jh8LP8AsZJv/TRqNd5Xz7q3jW+0fUvCMPii7l1u+8OeN5dOuL7TdNkL3PmaFdTxstvEHbIW6RTtz9wtwOnvIv4j/DL/AN+n9vb3oAfOf3tv/v8Apn+FvyqbtWHrPiiw0m80WG5MyNqF59lgPlPgyGKRwDxxwp6961BfRnGFl5x1ib29vcfr6GgV09Cx0o9Kri+jOPll5x1ib29vcfr6Ghb6I44l7f8ALJvb29x+voaBlgUyY/uZP909s9qiF9GcfLLz/wBMm9vb3H6+hpkt9GYX+WXlf+ebDsPbjqP19DQBbHSgVWW/iIGFl5x1ib29vf8An6UC/iP8MvP/AExf29vf/OKALNGarDUIjztl5/6Yv7e3vSf2jF/dm5/6Yv8A4UAWs1DB/rbj/fHbH8K/nTP7Ri/uzf8Afl/8Kgh1GLzbn5Zv9Z/zyc/wj24/z60AaFFVv7QiGflm4/6Yv/hQdQiGfll4z/yxf/D2oAs5oBqt9vjGfll/78v7+3t/nNKb6MZ4l/79N7+3sf09RQBIx/0hP91u3uO9SZqm97GLhPll4Rv+Wbevpjnof09RUpvY1zxLxnpEx9fb2P6eooAnzRVc30YzkS8Z6RN7+3sf09RQb6MZ+WXjP/LJvf29j+nqKALGajnP7v8A4EO2e4qM38Q/hl/79N7+3t/nNR3F/EIz8sv3h/yyb1+nt/nNAFztRkVW/tCIfwzf9+X9/b2o/tCIdVl/78v/AIUAWaKrf2hFn7s3/fl/8KP7Qi/uzf8Afl/8KALOags/9S3X/WP1XH8Z/wA5700ahEf4Zc/9cX9vb3qCy1CIxH5Zf9Y//LNj/Gfb3/D8KANDNANVhfxEj5Zef+mLe3t70ov42xhZefWJh6e3v/nFAFgUZquL6MgYWXn1ib29vcfr6GlW9jbHEvPrE3t7e4/X0NADl/4+pP8AcXt7t3pLy4NtAXVQ7kqqgnAySAP1NQJexm6f5ZeUTrG3qe2OOo/X0NMvrtJIUAEnMsRGY2H8aeo9/wDOKAHeZqX/ADxtf+/rf/E0CTUv+eNr/wB/W/8Aia5CfxF4/WeRYvCemyRBiEdtUILDPBI8virmg654yu9Vgi1Xw5Y2Fg27zLiG/Mrp8pxhdgzk4HXvQcqxEW7csv8AwFnR+ZqP/PG1/wC/rf8AxNNdtSYD91a9Qf8AWt/8TXlHxjF/aePvC9xpF/cWl/cQNEolnnNqGN/p8KyPArqrlUuZeD1yAa5y4+MviK/vnjsZ7M3El9DDYXk1rgJb3N5ZwpviWY5IWVz8xVjlcqvOQ6j3zfqX/PG1/wC/rf8AxNG/Uv8Anja/9/W/+JrwO0+LfiuDX7aONtO2m9hGpD7NITccaPC3lZf93zeysOv3UBBySb+i/E/WvFHwxk1bUNSs1uI/EOgIJ9MVoUjguJdNmeJiWOcC5dCcjcvUDJFAHtvmal/zxtf+/rf/ABNG/Uv+eNr/AN/W/wDia8W8V/GLxFpl3qVxaXenLpMU80kjLa+dNp1rbuyO7qZV84zYWRQNpEYcgOQM+i/DbxPf+IIdcTVZY5Lyy1KSAJDAESOMqrxgMHcSDawO/wCUnOCqkYoA6eC4uRciG5jiUshdTE5boQDnIH94VczWfcXCx6pbZDnMMo4QnunoKv8A4UAArzfx78I7rx/4s+23evmDw/LoV9oVzpMVovmSRXYXzXE+7KsDFER8pxtP97j0g0UAePXnhGbwjr3w3W+1NtZ1a/8AF1xeX2oNCsPnyHRb+NSEXhQsccaD2QE8k17DXB/Ef/kcPhZ/2Mk3/po1Ku86igDgfjbIbHwQurAZOj39rqrEDJ8uCVZJcemY1kH413wIIBHesfxdocXibw/faPPn7PqEE1pJg4+V4nU/XrWX8J9ffxP8M/DOpTNuuZtPhFx7TKoWUfg6sPwoMNqrXdfk/wDgnWUUUUG4Uyf/AFEn+6fftT6ZPnyZOv3T0OKAHjpRQOQKKACgUDrRQAVDb/625/66Dtj+FfzqY1DAT5tx1/1g6nP8K/lQBNRRRQAUUUUARsf9Jj/3W/mvepKjbP2hOv3W7+47VJQAUUdqM4oAOtRz/wCr/wCBL157ipKjm/1ff7w6HHcUASdaKBRQAUUGigAqCz/1Lcj/AFknQY/jNT1DZ58ps5/1j/ebP8ZoAnpKKM80AAoo7cUUARKf9Lk9di9vdu9Ran/x7p/12i/9GLUq5+1SdfuL346t2qLUv+Pdf+u0X/oxaALdJXml1d/F4XMwt9P8IG33nyzJcXIYrnjOF64q/wCGbn4lSa3bjxBZeGotJO7zn0+edpx8p27QygfexnPbNBgqt3blf3f8E7W40+1u5Y5Z7eKaWL7jyIGK/MrcE9PmRD9VB7CqcfhrR4JGaPS7KORpPOYrboCX3h9x467gGz6gGvKvjDrF34e8UmNJZhaahYDUMwkZt/sCzzPN83y8ySWK/Nx68ZrjLL4la3cRRaubuFLyaKGwn1NVSVYol1KS1e6BwE+WLdKTgIduSNvFBufRg0HTA/mDT7UPnduEK5zlDnp1zHGf+AL6CsHw38M9F0DRdT0ySIava6ldm8ulv4omWWTCKMoqhOBEn8PUZOSSa+fZviXrV/FZaLa+JprO0X7A099AsUTI32+wd7iMFSRE0Vy4YuSp+ZcYRierm+IfiRdVuNPsdWisJX1NdOisEtY2ZIHuI834yMkbpGhx93PPXNAHtg8G6AsfljRNOCZiO0WqYzGMR8Y/hHC+g6VesNKstKSVLK0gs0lkM0iwRhA7nqxwOSfWvPf+ErbS38J3WrahEbprO9t/MndYRd3CtEqgDgbnKkhR6nFed6f8VvEt0qRL4ssrpXiuIrK+VLeJLmY6etyJJVYfLFHIZEDJ0MeJM8mgD6Gk/wCQpb/9cZP/AEJKt81y3gnVzruiaDftNNctNZOWmnEYdyGQFj5fyHJHVPlPUcEV1HFABRQaKAOD+JH/ACOHws/7GSb/ANNGo13ma4L4j/8AI4fCz/sZJv8A00ajXe0AQXGPNts4/wBYev8Aut0rg/g5nTovF2gNsU6R4gu1jRf4YZyLqPj6XGP+A13s+fMt+v3znB/2W6153opGifH/AMTWQVhHrmi2mpqT0MsLvBJj32tBQc1X3Zwl52+9f5o9Koo7UCg6Q7VHOcQSdPunr9Kkpk2fJk6/dPTr0oAeOgo60dhRQAUUDrRQAVBBjzbnp/rBnH+6tTk1DDnzbjOfvjGf91elAE1HWjsaKADpRRR7UARsf9Jj6fcb69VqSo2/16dcbW+napBQAdKO9AooAKjuP9Xzj7y9fqKkNMmz5fGc5HT60APopRSUAFFFHpQAVBZEeS2Mf6yToMfxmp6hs8+U2d2fMf7x5++aAJu9FFHSgA+tFHajtQBCh/0uTpnYv16tTNRVmtsqpYrIjkLycBwTj8BUiZ+1P1xsX6dWqWgCl/aqZ/497n/vy1H9rJ/z73P/AH5artHagDPe/t5fv2k78FfmtyeD1HTocCojc2aR7PsMgQjbt+zHBB7Yx71q0yXOFxn7w6fWgDOM9m27OnyHcuxs2x5X0PHT2p32u137/sU2/GN32Y5xnOOnrzWlRQBmTXNpcBBLYSyCM7kD2xO0+o44NN82ywB/Z0mACB/op4B+8OnfvWrQKAM+1ZZr2ExQSQxRQumGj2AZK4AH/ATWhgUUZ9qADrRmiub+JXiW48GfDvxNr9pFHNdaXplzexRzZ8svHGzDdjnbkc45xmgDH+JH/I4fCz/sZJv/AE0ajXedK+epvila30nge+1zXNNv10Pxvc6bc6xp6FLWdv7HvXRlXc+DiZEIyRuDY4r30X9uekq/5x/iKAHXGPNtskf6w4z/ALrdK82+JLnQ/ir8M9bL+XBNc3eiTH+958PmRg/8Dtx+dehTX0BktgJf4+3+6ev5j9K82/aNuEj+GUmsW2JLzQr+z1eA4ztMU6Fz/wB+3f8AOg5cTpRlJdNfuaf6M9WzR0qrBqlrcwRSxzK6SKGUjuCAR/MfnTxfwHGJRz/9b/EfnQdO5OOKjn5glzj7p69OlMF9bkDEqnP/ANb/ABH50ya+gMT4lGSvGOvQf4j86BlrsKO1V11C3IXEqnP/ANb/ABH50o1C3OMSrz/9b/EUAT5oxVcahbnpMvP+f6ik/tC2/wCey0AWTUFuR51zjH+sGcf7i9aQ6jbf89lqGDUbfzLjMwxv7/7o6frQBe7UVX/tG25/fLxR/aFuD/rV/wA//qNAFjpRmq51C3H/AC1X/Of8DSm+gGcyrx/9f/A/lQA5ubmPp9xvr1WpRxVRr2EXCZlGArZ9Ov8A9Y/kalN9AucyDjP9f8D+VAE3SjvUBvoBnMqjHX9f8D+VBvoATmVeP/r/AOB/KgCc1Hccxdsbl6/UVGb+3HWVf85/wNMuNQtxH/rQMMOn1/8ArGgC3miq51C3Gcyr/n/9VH9o24/5arQBYo9Kr/2jbf8APZaP7QtuP3y0AWKgsceS2Mf6yT7v++aQahbdpl/z/wDrqGz1CAxHMvPmP97/AHzj+YoAvdKKgF/bkj96vP8A9b/EUgv7dsYlU5/+t/iKALHWjNQC+gIGJVOf/rf4j86UX0B6Sg5xj9P8R+dACpj7XJ0zsX69WqXFU0vYTdPiTgomPTqf8R+YqUX0DYxKvPT9P8R+dAE560E1AL+3OMSqc/8A1v8AEUn9oW5xiVef8/1FAFio5h8q9PvDr9ajGo2//PVf8/8A66ZLqFvhcSj7w6fUUAW6Kr/2jbf89loOo23/AD2XpQBY7UCq/wDaFuP+Wy/5/wD1UHULcf8ALVeP/r/4GgCxRwag+3wE481c/wD6/wDA1PzQAVV1S3mvNMu7e2mS3uJYXSOaSLzVRipAYpkbgDzjIz0zVqigDxlvA6eA9R+GFk00F3dXHiy5urme2tVtomc6PqCqEiUkIiIkaKMnhBkk5Nezdq4P4j/8jj8LP+xkm/8ATRqNd5QBBcY822yB/rDjP+61Zfjjw+vizwXr2iMdo1GwntNw6jfGyg/rWrPkyW+M/wCsPQf7LdfSpiaCWlJNPqcB8BPEJ8U/BzwlftnzPsCQSbuu6L92c++Uz+Nd/wAV5F+z2f7Gbx14WY7f7H8QXJgh/wCedtMfMhH5ZP4166KDmwsnKhG+6Vvu0/QKjuMeRJ0xtPXp0qTNMnz5MmM/dPQZ7UHWOHQUv4UDpRmgAoxSjrSUABqC3x51zwP9YM4/3F61OTUMGRLcZzzJxkY/hWgCajiiigAoozRQBE2PtMfTOxvr1WpajbP2iPrja3bjqKlFACCjiiigAqO4x5Xb7y9fqKkqOc5j7/eHQe4oAkooooAOKKKKACq9jjyWwFH72Tp/vmrFQWefKbOf9Y/3hj+M0AT0UZooAKO1GaM0AQrj7XJ0zsX69Wqaolz9qk642L246tUpoAKKKXNACVHNjC9PvL1+tSZpk3Rev3h0HvQA+jvRRQAUUUUAFLmkoNABR3oooA4P4j/8jh8LP+xkm/8ATRqNd5XBfEf/AJHD4Wf9jJN/6aNRrvfwoAhuOZLbp/rD1P8Ast0qbtUM/wDrbfr/AKw9s/wt+VTUAeQaF/xTn7TfiWzBxD4g0e21EkjGZYyYQo/4DGzfjXr9eP8AxaI0D4s/DPxCflha4n0uUj+JpgojB9gDM34V7BQcWH92VSn2lf70n+dwpk/+ok/3T1OO1Ppk/wDqJP8AdPQZ7UHaPB4FAoHSigAzzRR3ooAKgt8ebc9P9YOh/wBhetT1DB/rbj/roO2P4V/OgCalpKOtAC0lFBoAjbH2mPp9xu/utSVG3/HxH/ut29x3qSgAooooAKjuMGPt95evHcVJUc/3OP7w6DPcUASUUDmjigAooxRQAGoLLAhbGP8AWSdDn+M1PUFn/qm6/wCsfqMfxmgCxmkoo/CgAFFHaigCJcC7k6fcXvz1apqhX/j6k642L29271LQAUZoNH4UAHamTYwvT7y9frT6ZL0X/eHbPegB9HWjvQaAFopKKAA0vFJ3oNAB1oorK8Xa1P4b8Ka1q1tYy6pcWFlNdRWMH+suGSNmEa+7EAD3NAHMfEgf8Vh8LP8AsZJv/TRqNd5XzoPjJa6/afD7xJ4g1PRrfTLHxjNaDW7GcjT7pTot6Q8bPzgPKYTk/fjb6V9BDUrQ9LiL/voe3+I/OgB8/wDrbf8A66euP4W/Opqoz6jatLbYuIz8/HIOflP5dR+fvUw1G1bGLiM5xj5h3xj+Y/MUAed/tB6OuqeBIJywjaz1C3kEp6QiRjbNL/wBJ2f/AIDXa+EtcHiXwxpeqbPLe6t0leP/AJ5uR8yn3DZH4VD4qsbDxX4Y1bRprlFi1G0ltWZWGQJE25Hv84I+orhvgH4vTVvDFxbXcscV5HMLl4s42tMA8q/Rbg3Cf8AFBwv3MSn/ADK3zX/APVqZP/qJP9098dqhGo2pxi4j56fMPb/EfmKZNqNo0L/6RHyvHzA9h2/EfmKDuLg6UVWGpWpAxcRnOMfMPb/EfnQNStDjFzFz0+Ye3+I/OgCzRVYanaHn7TFz0+ce3+IpP7Us+P8ASYuf9sUAWqhtx+9uP+ug75/hX8qjOqWf/PzF/wB9ioYdUtBLc/6TF/rPUD+Efn/n0oA0KDVU6naD/l5i/wC+x/nsaU6nac/6TEMdfnHv/gfyoAs0Cq39p2gz/pMXH+2Pf/A/lSnUbUZ/0iPj/aHv/gfyNAEjDNzH/ut3917VJVN9QtVuEzPGMI+eR2PPP/AT+R9KkOoWyZzcRjGc5Yds5/8AQT+RoAsUdarnULVc5uIxjOfmHGM5/wDQT+RoOo2q5zcRjGc/MPf/AAP5GgCxUc/+r/4EvfHcVEdStVBzcRD/AIGPf/A/lUdxqdosfNzEMMOrA9//AKx/KgC7RVb+07QZzcxDH+2Pf/A0f2naf8/MQ/4GKALNHeqp1Szz/wAfMX/fYo/tS0/5+Yv++xQBaqCz/wBU3/XSTvn+M0wanaHpcxH/AIGPb/EVDZalaGJsXMRzI/cD+M/4jnv+NAGhQKrDUrViMXMXPT5x7f4j86UalatjFxGc9MMPb/EfnQBYoquNRtSBi4iOemGHt/iPzFC6hbNjFxGc4xhuucf/ABQ/MUAPX/j6k/3F7+7dqlqkmoWrXT4uI+UTHI7k45/4EPzHrUo1G1bGLiM56fMOc4x/6EPzoAsUVWGpWpx/pEZz0+Ye3+I/OganaED/AEmLn/bHt/iPzoAsmo5vur/vDvjvUQ1S0/5+Yv8Avsf57j86jl1Ozwv+kxfeX+IHuKALvWiqv9qWZ/5eYv8AvsUHVLMf8vMX/fYoAtUVWOp2gz/pMXH+2P8APY0f2nac/wCkxDHX5x7/AOB/KgCzRmq/9o2pOPtEefTcPf8AwP5VY59aADrWH478NHxn4I8Q+Hlu3sG1bTrixF3GMtCZYmTeOnI3Z/Ctw9aO1AHhlv4L1Lwr4j8Dy61Jp8moav40mvpYNLiZLWDboF3AqRhueRAHOf4navc8CuC+I/8AyOHws/7GSb/00ajXe/zoAhnH7y3/AOunrj+FvzqbAqGf/W22cZ8w9R/stUxoAMCvG/CRPhL4zazpRGy2vJ5fLXHVZwbuI/8Af0akPyr2TtXj3xljk0DxZoniGBT80Do+3q8tq32qNfxgW/X/ALaUHFi/dgqi+y0/8z2HAFRzAeTJ/unvjt606N1ljV0YMjAEEdxTZ+IJM/3T1+lB2jwBS4FHYUUAGBRgUUUAGBUEAHm3H/XQd8/wr+VTmoIMebc4x/rBnAx/CvWgCcgUYFFGKADAowKKKAI2H+kR/wC63f3HapMCom/4+I/XY316rUooAMCgAGijrQAVHOB5f/Ah3x3FSdqjn/1eePvL157igCTAHpRgUUUAGBRgUUGgAwPSoLMfuW/66P1Of4z/AJ9qnqCy5hbGP9ZJ0GP4zQBPgUYH+RR1ooAMCjAo7UdqAIkH+kyf7i9/c9qlAFQp/wAfcnTOxe3PVqm9aADAowKDR0oAMD2qOYDC/wC8O+O9SVHLjC/7w/nQBJgUYFFH8qADAowMUUUAGBRjNFHHegA60Ud6PSgDg/iR/wAjh8LP+xkm/wDTRqNd5iuD+I//ACOHws/7GSb/ANNGo13lAEM2fMt+v3+cHH8LdamqG4x5tt0/1h6/7rdKmJoAK4b4zW23wNPqgTzH0SeLVSuOTFEwM6j/AHoPOT/gVdzxioby0h1CzntbhBLBNG0ciN0ZSMEfkaDOceeLj3Oa+GE5/wCEPtbCSTzZtKeTTHbuwhYojH/eQI//AAKuom/1L4z909ODXknwMuZtMluNGupTJcfZwjux5luLNzZTv/wJYrZ/+2me9etT48iTOMbT1+lBjhZc1JeWn3f8CxJ2FFA6Cig6g6UYo70dqADrmooM+ZPnON/GTn+FelSmoLfHnXOMf6wdP9xetAE9FHaigAFHWjrQaAI2/wCPhOuNrfTtUlRNj7TH0zsb69VqUUAFGKKKAA0yf7nGfvDp9RT6juMeX2xuXr9RQBJRiigUAFFFFABUNpnymznPmP8AeOf4jU1QWWPJbG3/AFsn3f8AfP60ATiijrRQAe1H40dqPWgCJc/aZOuNi9+OpqWoU/4+5Omdi/Xq1TUAHejNFGeKACmS5wuM/eHTjvT6jmxhen3h1+tAElFHWigAo6UdKO9ABRjPeigmgANFYUvjrw/D4lsfD76rbrrN8Jjb2e755fKAMgHuoOcdeG/unGrqX2saddGwELX3lN9nFwSIjJg7d5HO3OM45xQBxfxH/wCRx+Fn/YyTf+mjUa7yvB08canrt94C1DxT/ZOnmx8cX2nC4sZ3+zSCHStQic7pACCJhKn1T3r3QTx/89EP/AqAEnz5lvjON/OP91utS9qqzzRGW2/eJnzOMt/st0/Op/OjPSRf++h/nuKAH0oqMTR9pFP4/wCfUUCaM4+df++h/nvQB49fBfCXxdup87IZby1v8jj91dp9jlQD0E9vayH/AH69hn/1MmM52np1rzP4vaPFf6p4duROkIvBc6FLMcERC4jDwyfVbi3twPd66/wt4jXxL4StNQlCQXMsJW4gLf6qZcrKn/AXDD8KDho+5VnT76r9ToAeBSiohPHgfvE/76FKJ4v+eif99UHcSUlM8+L/AJ6L/wB9Ck+0Rf8APRD/AMCFAEnaooM+ZcZ3Y8zjP+6vSlNxF/z0T/voVDbzw+bdfvI/9YOjf7C9aALXSio/tEQz+8T/AL6FKJ4h/wAtE/76FAEgoqPz4v8Anon/AH1QZ4wP9Yn/AH1/n0oARs+enXG1vp1FSVXeaIXMeXT7jfxc9R/h+lS+dGM5dR/wIf57GgB4o4phmjH/AC0X8SP89j+VBnjH/LRR/wAC/wA+hoAfTJ8+XxnqvT6ijz4u8iD/AIEP89qjuJ4hHzIn3h1b3/8ArUAT0Uzz4v8Anon/AH0KPtEWf9Yn/fQoAfR2qPz4v+eif99Cjz4v+eif99CgCSobTPlNnP8ArH+9/vn9KcJ4v+eif99CoLGaHyWxJH/rZPut/tmgC5SUwTxf89E5/wBoUefGekif99D/AD3oAfiimCaM9JF/76H+e4/OgTRn+NT+I/z3H50ANXP2qTrjYv06tU3WqyTRm7k/eJkov8XPU/4/rUvnR9nX/vof57igCSio/PjP/LRf++hR58X/AD0T/voUAPxTJei9fvDp9aBPF/z0T/voVHNPFhf3ifeHVvcUAWKPaovPi/56J/30KPPi/wCeif8AfQoAk6UtR+fEP+Wif99Cjz4v+eif99CgCSjHvUYmiz/rF/76/wA+9SZpAeAQW+kW37QGnEXmq3Vxd6o80CGCL7LZtHa6inlFgd/715b+QMQeYNpwNuffjXg9jbpa/HdNTbRNLXTtU117KC6ivJjfi9t9OuT5kkZ/drEY2ulCLzmVZDkuce8UwPFNW8BQafpnwd0DX7Ox1KV/EU9xqMTRCW3mu5NM1OeZwrjkGZ3YZGeh617L9itx0gi/74H+ew/KuJ+I/wDyOHws/wCxkm/9NGo13lAFSezgWW2xAgxJ2Qf3T1/IfkKlFnAAMQRj0+Qe3+A/IUlwB5ttnGfMPU/7LdKnPpQBCLO3GP3EYx0+Ue3+A/IUosoBjEEYx/sD2/wH5Cpf5UDmgDkviZ4ZbXPA2qwafbodThjW7sQqgZuYWWWEZ9C8aA+1YXgTUtNudUuzZRqdL8QWUfiDTsxgEb1VZ0A7EN5Tkesp9K9KrxOaN/B9zrNsiAf8IvqP9r2ygY3aVeb/AD147I/2ggekEftQcOI/dyjV7f1+V/uPZhZW4xiCMYx/APb/AAH5UCytx/ywj4/2B/nsPyqVSGUEEEEZBFKKDuIfsVsP+XeL/vgf57Cj7Dbcf6PF/wB8CpsUUAQ/YLb/AJ94v++BUMFjbmS5zbx/6zug/ujp/n1q5UNvgS3PQHzB0P8Asr1oAPsNt3t4v++BR9htjn/R4v8Avgf57mpqKAITY2//AD7xf98D/Pc/nQbK3P8AywjOf9ge/wDifzqaigCs9nAbhMwpgq2fkGOo/wAT+ZqQ2cDZzDGc+qj3/wAT+ZobH2mPp9xu/PValoAhNnAc5hjOeuUHPX/E/maU2VuxP7iP3+Qe/wDifzNS9qKAITZW56wRf98D3/xP51HPY25j/wCPePqOiA9//rn86tVHcY8rt95ep9xQA02NuetvEc/7A/z60Gxtv+feL/vgVNijNAEBsLb/AJ94v++BR9htv+feL/vgVPRQBD9hth/y7xf98CoLOxtxEf3Cf6x+sYH8Z/wH5CrtQWWPJbGP9bJ0Of4zQAosrcEYt4xjp8g9v8B+VKLK3AGIIxj0Qe3+A/KpaKAIhZ246QRjHTCD2/wH5CgWcA6QxjHT5B7f4D8hUtFAFVLOAXT4hQAIuPkGByf8B+QqX7HbjGIYxjp8g9v8B+QpFx9rk6Z2L356tU1AEIsrcf8ALCMf8AHt/gPyoFlbD/l3i4/2B/nsPyqbrRxQBD9hth/y7xf98CmS2FthcW8f3h0QeoqzUc2CF6ffHX60AM+wW3/PvF/3wKPsFt/z7xf98Cp6KAIfsNt/zwi/74FH2G2P/LCLn/YH+e5/OpqKAIvsdvnPkR/XYPf/ABP51LjNBpfyoA+fLXxd4J8V/G7wnqXhbRdQi8S3V/NFqupXGgXdsHtV0+5HzyyxKv8ArEtxkHJ2qORxX0FRiigDg/iP/wAjj8LP+xkm/wDTRqNd5XB/Ef8A5HD4Wf8AYyTf+mjUa7ygCGf/AFlv1+/2Gf4W/KpqhuMebb9P9Ye+P4W/OpjQAUdKMUUAArzz4l28Wj694f8AEUqbrJ2fQtSXGQ1vdFVjJHfbOsI9hK9eh1j+MfD0Hivwrq+jXLFIb21kgLr1QlSAwPYg4IPqBQZVI80Wlv8A1/XzMz4bXEkegSaNcu0l5oc7abIz/edEAMLn1LRNGx9ya6uvKvA3iG4n1TQNXvVWK41q2fSNUjUYWPU7QuD+B23Az3CR+1eq9KDLDSvDl7afLp+FvuYUUdTRQdQGoYP9ZcdfvjqMfwr+dTEVDBjzbnoP3g75/hX8qAJqKKKADHFFFFAEbf8AHxH1+63b6VJUbD/SI+n3W7+69qkoAKOtFFAAajn/ANWOv3h0Ge4qSo5/9X/wJe+O4oAkooo/WgAooooAPaoLPiJs5/1j9Rj+M1PUFnxC3T/WSdDn+M0AT4oFGaOlABRRRQBEv/HzJ1+4vb3bvUuKiX/j6k6fcXv7t2qWgA60UUdqACmS9F/3h2z3p/emTdF6H5h3x3oAfRR3ooAMUUdKKACjg0UY9qADNFHSs/xDrtl4X0DUtZ1KUQafp1tJd3MpGdkUal3b8ACaAOT+I/8AyOPws/7GSb/00ajXeV43d+NX8Y3Pwq1m7tbbTEfxRcIEi1CK7QAaTqI5kT5QwOVK9iCMnrXsW9f7w/OgCOf/AFtv/wBdPTP8LflU3WoJ3UyW/I+//ex/C351LvX1FADqKTev94fnQHU/xD86AFqOf/USf7p7Z7U7ev8AeH50yZlMMnzD7p747UAeT+INFms/FXiTRbMBZtWhj8S6RkAAX9sUWZB6BttsT6+ZJ716b4e1u38SaJY6paEm3u4VlUN1XI5U+hByCPUGuU+LIOm6NYeKIOZ/Dd0uoSbeS1rgpdL7/uXdgP7yLUnh+aPwt4xu9GDqdL1gPqemsD8qy5BuIgfcsJR/vv6UHAv3Vbyf67fjdfNHb0U3ev8AeH50eYv94fnQd44ioYP9bc/9dB2x/Cv51J5i/wB4fnUMDqJLj5h/rB/Fn+FfyoAsUU3zF/vD86N6/wB4fnQA6ik3rn7w/Ok3r6j86AGt/wAfEf8Aut29x3qTNQs6/aE5H3G/i9x2qTevcj86AHCim71/vD86N6/3h+dADqjn/wBX/wACXtnuKdvX+8Pzpk7r5f3h94fxY70AS0U3ev8AeFG9f7w/OgB3U0U3ev8AeH50b1/vD86AHe1QWf8AqW/66Sfw4/jP+c1LvX1H51BZuvlN8w/1j/xZ/jP+fagCzRSb1/vD86A6/wB4fnQAtFN3r6j86XevqKAI1/4+pP8AcXt7t3qXvUCsPtUnI+4v8Xue1S717MPzoAdRSb17EfnQHX+8PzoAWmTcBf8AeHbPel3r/eH50yV1Kr8w+8O+O9AEvWim71/vD86N6/3h+dADqKTzF/vD86Tev94fnQA6jNJuX+8PzpwzQAhrnfiN4SHj34e+J/DBn+zDWtLutO8/GfL86Jo92Pbdn8K6LpRQB87Wfw/mtdQ8HReJfD2mabFrPjZ7waDAy3NtbLH4fuYAM7Qpy1uZeFGN47g19CC0g/54xj/gI/z2riPiP/yOHws/7GSb/wBNGo13lAFSe1gEtt+6jH7zj5Af4T+XQflUwtYR0iT/AL5Ht/gPyon/ANZb4z9/scfwt19alIoAiFrCOkScf7I9v8B+VAtIRj9ygx/sj2/wH5VL2o60ARC0hGMRJ/3yPb/AflTJ7WAQSfuoxhT/AAD0/wDrD8qsUyb/AFMmM/dPQ47UAQz6ZaXVs8E1tFLDIhR0ZAQykYIPtivJdG0K4fw/qPg4bD4k8ITRXOj3E3W4thk2rMe4Kq9u59UY9xXsY5Arz/4nwv4budN8c2iFpNF3R6iiDJm05yPO4HUxkLKP+ubAfeoOWvBSjzP5+n/A0a9DqPDWp2PifQrLVLaBUiuIw3lugDRt0ZG9GVgVI9VrS+xwf88I/wDvkVx2jyx+GPG01nG6to3iINf2UinKLcgZmQHph1xKPUiU129BdKbnG0t1o/689/mQmzg/54R/98ioYLO3Mtz+5iP7z+4B/Cv51cNQwf6y46/6wYyc/wAK9PSg3FNnBz+5j/75FH2OA5/cx/8AfIqWjpQBF9jgOf3Kf98j/Pc0ptIT1iQ/8BHv/ifzqSigCs9rCbhAYozlG/gHt/ifzqU2sRzmJD/wEe/+J/M0N/x8R9fut346jtUlAEf2WE5zEhz/ALI9/wDE/nSG1gOcxIfX5R7/AOJ/OpaKAIjaQH/ljGf+Aj/Pc/nUdxaQGPmGP7w6oD3/APrmrNRzf6vv94dDjuKAENnAf+WMZz/sik+xwf8APGP/AL5FTUdKAIfscH/PGP8A75FL9jg4/cx/98ipaKAIvscA/wCWMf8A3yKgsrS38k4ij/1j9EA/jP8AhVzNQ2f+qOc/6x/vHP8AGaAFFpAOkMfH+yP89h+VAtIB0hT/AL5Ht/gPyqX6Uv0oAh+ywgDESDH+yPb/AAH5UC1hA4iQY/2R7f4D8ql7Zo7UAVUtYRdviKPhE6IM9T3/AAH5VMLWEf8ALJOP9ke3+A/KkX/j5k642L346t2qWgCL7JCCMQx/98j/AD2H5UfY4B/yxj4/2R/nsPyqWjtQBF9jg/54R/8AfI/z2qOWzgCr+5jHzL/APWrOPemS9F6/eHQ470AM+xwf88Y/++BQbOD/AJ4x/wDfIqY0ZoAiNnB/zxj/AO+RR9kgP/LGPn/ZH+fWpaKAIvskPXyk/wC+R/nufzqUiijIoAKKXFJ+NAHBfEf/AJHD4Wf9jJN/6aNRrva4P4j/API4/Cz/ALGSb/00ajXeUAQz48226cyHr/ut0qaop8+Zb4z/AKw5x/ut1qU9KACgUoFJigAqOf8A1EnTG09fpUmKZNxDJjOdp6daAHjoKbJEk0bxyKHRwVZWGQQeoIpw6CigDyDSNDnj0/V/h+JhFqmgPHqPh25lOf8ARtxNvz1IjYNA3+wFz9+vSPCfiKLxVoFrqMSGF5AVmgY/NBKp2yRt7qwIP0rm/inZXGmQaf4w06J5dQ8PO000MQy1zZMALmIDudoEij+/EvrVe8vYPCGsw+KrCVJvCmueW1+0Z/dwyMAIrsf7LAqr/wDAW7Gg86/sJ36dfTo/ls/K3Y9DqGDHm3OMf6wdP91etTDkcHI9ahgz5txnON/Gf91elB6JNRRRQAUfzoooAjbH2iPpna316rUgqNs/aI+v3W+nUVJQAdKMZoooAOtR3GBHzjG5ev1FSUyfiPv94dPqKAH9qSnYpKACjrRRQAdKgssGJsY/1kn3Rj+M1PUNpnymzu/1j/e6/fP6UATdKOtFFAB1oHSjtRigCJMfa5Omdi/Xq1Smolz9pk642L9OrVKaACjiiigAqOXovT7w6/WpRUc2cL1+8On1oAfRRiigAoFFFABRijFFIAoo7Vl+Ktej8K+GNY1uaN54dNs5rx40IDOsaFyBnudtMDl/iP8A8jh8LP8AsZJv/TRqNd50ryjVteufEuo/CTUbuwTTZJvEs5ECXSXK7f7J1IA70+U59uler0AQ3GPNts4/1hxn/dbpU3WoZ8+Zb4J/1hzj/dbrU1AB1o6UCigAqO4/1EmcY2nr06VJTJv9RJjOdp6delADx0ooHQUA0ABwcg8g15foEMfgTXZPAeqxrP4Z1UStockwygUgtLYN/ujLR+qZX+Dn1DrWF428I2njjw9caZdO8DErLb3UPEtrOpzHLGezKwBH5dCaDGpByV47r8e6+Zi+C7yfwzqsng/UpnmMMZm0m7lPNzajjyye8kWQp7ldrdzXYW+PNucY/wBYM4/3F615rps978QdCudH1J49L8f+G5lbz0HyiUA+VcoO8My5yPQup5Wuu8D+KF8U6dczSRNZ6hbzGC9snOWt5lVQy+47g9wQaDChNR/d9Onp1Xqvy9Do6MUUUHaFFFHagCJubmPpnY316rUtRnP2hOuNrfTqKkoAKCKPxozQAVHP/qu33l6/UVJUc+fL4JzuXp9RQBJR0oooAKDR+NFABiq9jjyWxjHmyfdz/fNWPxqCzz5LZz/rH6j/AGzQBPRR+NH40AHWjtQDR+NAEK4+1y9M7F+vVqmqJc/apOuNi9uOrVLQAUdaKKAAVHNwq9PvDr9akzTJug6/eHT60AP70Yo/Gj8aACij8aKADGKOvrRS5oASqOvRmXQ9RRbBNVZraRRYSMqrc5U/uyW4Ab7uTxzzV7BooA+dj8PES68HWOseH4dE0nVvHNxe2vh6ORdllENEu1C5iO0F5InmIQ4BlPJ5r6C+wwDH7sfn/n0FcV8SP+Rx+Fn/AGMk3/po1Gu8oApT2UAltv3a58zjJP8AdPT8hU4soR0jHHTk+3+Aonz5lv1+/wBhn+FvyqagCEWUIxiMcfX2/wABQLKAY/dgfifb/AVNR6UAQCyhHSMcf/W/wH5UyaygEEn7teFPUn0H+Aq1zTJx+5kxn7p6c9qAIxYwADEY49z7f4CgWMAx+7HHufb/AAFTjpQKAIPsMA/5Zj8z/ntSfYLf/nmPzNWMZNFAHn3xH8G3KzWnivw5bLJ4i0lSDahto1G1PMlsx9T95CejgdiazTYweKLSHx54IMc17Iq+baOxRL+IKN0MoP3JUO4A9VIIPBNep4ryvXNI1T4Y69qninw9bz6joV1N5usaBCuWDbV3XVsO793T+Pkj5hyHFWprV9Ott0/5l+v66nbeF9Z0rxfpK31kpA3GOaCUFZYJRw0br/CwPUf0rX+wQHP7sfmf8964C7iF4IPHvgeWPURcxB7uzgbEepwgcEf3Zl5wT/ut7dn4c8RWPirSINS0+XzbeUHgjDIw+8jL1VgeCD0NBpSqtvknv+DXdfqunpZlz7DB/wA8x+Z9/wDE0psoDn92Pz+v+Jqaig6Sq1nCblMxrko3c56j/E/nUhs4WzlBzn+v+J/OnNn7QnX7rduOo71JQBCbKE5zGOevP1/xNBsYTn92Ofc+/wDiamooAgNjAesY/M+/+JqO4sbcx8xqfmHUn1/+vVvPFRz58vv94dBnuKAGGwg7xj8z/nvR9gg/55j8zU+OKKAIDYW//PMc+5o+wW//ADzH5mp8Ue9AEAsIB/yzH5n/AD2qCysbcRNiNceZJ90n++f8KvdagtM+U2c/6x+ox/GaAAWMAx+7HHufb/AUCygGMRjjGOT7f4Cp6MY+lAEAsoQBiMce/wBP8B+VKtnCMYQDHTn6f4CpsUUAVI7OAXb4RchE7nPU/wCAqUWUIxiMcdOfp/gKVf8Aj5k6/cXtx1bvUtAEH2GAY/djjpyfb/AUCxgGP3Y/M+3+AqeigCD7BAP+WY/M1HNYW4Vf3a/eXqT6ireKZLnC9fvDoM96AI/sEH/PMfmaT+z7fH+rH5mrFFAEBsID/wAsxz7mj7DAc/ux+Z9/8an70UAQiygBz5Y/P6/4mpuTRjmjFABQaM0UAcH8R/8AkcPhZ/2Mk3/po1Gu8xXB/Ej/AJHD4Wf9jJN/6aNRrvAaAILjHm2/A/1h6n/Zap6hn4lt/wDroe2f4W/Kps0AFFFGaAAVHP8A6iT02nqfapM0yf8A1En+6e2e1ADuwpaB0ozQAUUUZoAKgg/1tzwP9YOhz/Cv5VYPFQQf625/66Dtj+FfzoA8117w/qPwu1e78TeF7WS+0W6kM2s+HoBkkn711bL2k7sg4fqPm6zjTzqUaeNvh7f29x/aCia4sWfFrqIxjJ/55yjGN2Ooww9PSTXmeueBNb8Iaxd+IfAckWbljNf+G7ltlrev3kib/ljMfX7rH7w70HDVo22Wm+m6fdfqv+Cjq/CXjaw8XRTpEslnqNqdl3p10Nk9u3oy9wezDIPY10NeWWl7ofxdZrrTp7nwx430sbZI5UEd7ZnP3JUPEkR/FSDwQa29D+IcllqKaH4uii0bWidsM4J+yXw/vROeh9Ubke9AQr8tlUej2l0fr2flt27HZsP9Jj6Z2N391qWo2P8ApEfpsbt7jvUlB3AKO9GaM0AB5qO4/wBX0/iXqfcVJ2qOc/J3+8vbPcUASdKKKM0AHeijNFABUFljyW4GPMk6HP8AGan61BZn9y2c/wCsk/hx/GaAJ6KM0UAHWijPFFAEKf8AH1J0zsXv7tU1RIf9Kk/3F7e7d6l6GgAoooFAB07VHN91f95e/vUlMmPC/wC8O2e9AD/pRR7UUAFHSijtQAUZopfzoAQmiig0AcH8R/8AkcPhZ/2Mk3/po1Gu8ryG88d6Z8RtU+GGr6QZWsV8YX9mskqgeYYdN1SIuuCcoxTcp7qQcDNevUAQz8y23/XQ98fwt+dTGobj/W2//XQ9s/wt+VTdqACgGiloAQUyf/Uyf7p747U+mT/6iT/dPbPagB/YUdKOwooAKKOpooADUEH+tuf+ug/iz/Cv5VPUMH+tuef+Wg7Y/hX86AJqAM0UUAcj44+GmmeNZLa+8ybSdessmz1mxbZcQe2ejIe6NkH0ritR8atoNkfD3xb0uCSwlIij8Qw25fT7kdjKOTbyfX5c8hvT2PvUdxbxXcLwzRJNC42tHIoZWHoQetBzzoqV3HRvfqn6r+meaWuk674PFteeEr9fFXh1oyy6XdXIaRI8j/j3n53D0V+OMAjNdX4U+IGk+LWlt7eR7XUoOLjTbxfKuYT7oeo9xke9cjf/AAbfw7qZ1H4f6s/hS7YM8mmshm024ORndCT+7z6xlT7Vz3iHxXpc0kdp8VfDMnhy/hOLfxDYs72jHpuS4TDxeu2QD8aDi9/D7aLs/h+T3j6PQ9zo9a8u0eTxRpdgl74Z1+y8f6JjKxXcyrc7fRJ0+Vj/AL4/GtvSPi3ot1dLY6ss/hrVTx9j1ZPJLH/Yf7jj6Gg6Y4mGiqe6/Pb5PZ/evQ7ao5xiP/gS98dxT0dZUDowdCMgqcg0yf8A1f8AwJe2e4oOwkoo5ooAO9HpRRQAVBZf6lv+ukn8Wf4zU/WoLL/VN/10k6DH8ZoAnFHeg0UAB6UdjRRQBEn/AB9Sf7i9/du1S1Ep/wBKk/3F7e7VL0oAKMUvvSdqACo5ei/7w7471JjNMm+6v+8Ooz3oAf3NB7UUUAFAo7UUAFGaPaloATpWP4x0zUda8Ja3p2kX40rVbqymgtL4qWFvMyFUkwCM7WIOPatiigD5k8PfDXWdL0fwF4b8XpawK3jzUZLdNCM1kq2/9nai0e0rIXUEgkAMPlIU98/SYsYh3k/7+t7e/tXF/Ej/AJHH4Wf9jJN/6aNRrvOtAFKayjWS3wZPv/8APZv7p9+eg/zmphZRjGDJxj/lo3t7+w/yTSz4Etv05kOMj/ZbpU1AEAsoxjmTj/po3t7+w/X1oWyjGOZOOn7xvb39h+vqanxR+FAEAsohjmTj/po3t7+w/wAmmTWUYifBk4X/AJ6sOw9/YVapk/EEmcY2nr06UARLYxADmTj/AKat7e/sP8mgWMQ7ycf9NW9vf2qwOgooAr/YIvWT/v63t7+1J9gi9Zf+/rf41ZooArf2fF6y/wDf1v8AGoobCLzLjJl+/wB5mP8ACPfirx6VDb4MtzjBxIM4H+yvWgBv2CI55l/7+t/jR9giOcmT/v63v7+9WKKAK/2CIg8yc/8ATVvf396U2URzzJz/ANNG9/f3P+RU4FFAFR7OMzrzJyrZxKw7+mfc/wCcU6bTre4jeORWdHBDKzsQQc54z7n/ACBUrf8AHxH0ztbtz1WpMUAea6p8APC811NfaH9s8IapISWvNAuGtixJydyD5G/FawdU8L+P9Jt3tNUsdJ+J+iEkeXcH7Hegc4JBzE5Gccbe3TFe0Hiig5pYeD209P8ALb8D5pm1vwz4YYxzDxj8KbjP3ZYZJrAk98rvjI+hH4V2Wh+L/EU9sJbS70T4gWHH+kaJqP2e4HPVkLFSTnoCK9ikjWVCjoHU8FWGQa4XxL8EfA/iJzcXXh60t7skf6XYhrWYcj+OIq360HJ9UnT1pSt6afhrH8EUf+Fu6DYP5evWGt+G5c4P2+2l8sH2kTcpHPXNdZo+u6B4hj36Zq9vfqef9HvN5H4BuOtcQPgdf6UCNB+IXibTl/hgvZo7+ED02zKePxrmda+DXjGU+Y8PgzxHKvIlmsZdNuD/ANtIWbB/AUBz4unvHm/ryf6HuX9nxesn/f1v8aPsEXrJ/wB/W/xr5wGh/ETw+2bbw34msUXoNL8SQ3kQ+kc4BI9iasRfFzxxoalb6LWogvbWvDDsf+/lq7DHvtoD684/xKbX4/5H0QLCId5P+/rf4+1Q2dhEIjzLxI/WZj/Eff2r5+i/a0awk8rULTSZm/vJdy2n6TxLzWzo37V/ht0C3dhNDl2O6zure4Xliegkz+lBSzHDPeVvVP8A4J7cLGJSMGTj/pq3t7+1KLGJcYMnH/TRvb39v85rzu1/aJ8E3ABa9u4B1zLYy4/MKRWpZ/GzwLfECPxPYK3pLJ5Z/wDHsUG6xeHltUX3o7AWUS45k49ZG9vf2H+SaFs41xgvxj/lo3t7+w/X1NZVp468OX2Ps+vaZNnsl3GT/OtWDULa5XMNxDKPVHB/lQdEZwl8LT+aI47OMXTcycIv/LVj3PbPsPr+dSfYoxjBk49ZG9vf2H6+tKjA3UmCCdi9OvVqmPegsg+wxDHMnH/TVvb39qT7BFxzJx/01b29/arH60fhQBXFhF6yf9/W/wAajlsItq8y/eH/AC2Ydx71c7UyboucfeHUe9AEP9nxesn/AH9b/Gj+z4cdZf8Av63+NWaOvagCv9giPeT/AL+t/jR9giPeTn/pq3v7+9WKKAIBYxZzmT/v43v7+5qeijigAzRRmj8KAOD+I/8AyOHws/7GSb/00ajXeVwfxH/5HD4Wf9jJN/6aNRrvM0ARTE+ZB1+/zg/7LdalP6VBcsomtQSoJkIUHudjdPfr+tT9qAAUuaTpRQAUyb/UvjOdp6delP61HcELbylsABTnPTpQBIOgooB4FGaACj60UUAGahhyZLjOcb+5/wBlelTc1BbMGmugCpIlAbHUHYvX3/8ArUAT0UUdRQAUUZ5ooAjYnz06/dbvx2qQVEzAXcY43bGIHfqtS0AAoopc0AJTJz8nGc5HT61JmorkhYstgDcvX/eFAElFHaigAoo7UUARTW0NwpSWJJFPBV1BB/OuYm+GXhHWIn+3eF9JumMj5M1lEzfePfbXW5qtYMrwMVKkebIPl6ZDtn8fX3oJcYy+JXPP7r9nH4aXZJfwbpiH1ijMeP8Avkis66/ZZ+HF0Mf2NPCOwhv50x+T16zRQYPDUJbwX3I8Ku/2NPh9c58p9ZtQe0WoMf8A0IGqL/sU+D1O6DXvEduw6FLyPj846+gxRQYPL8I96S+4+fE/ZKjtZGSx+Ifi2zCqCCLlCO/oo9Kd/wAMzeK7Y/6H8Y/EkOOnmx+Z/wCzive0YfbZVyu4RqSO+Mt/n86moD+z8MtoW9G1+p4CvwF+Jtv/AKj4z6i4/wCm1gD/AO1DUifCD4v2/wDq/i6H/wCuumA/+zV71S0D+o0el/8AwKX+Z4Unw4+NcP3Pihp0n/XTSR/jT28F/HSEDHxC0KXkcNpOO/tXuNRzkBVyQPnUc/Wgf1SmtpS/8Cf+Z4ynh347RH/kbfCs/wDv6fIP5VJ/ZXx4Xprngx/960nH9a9mooK+qx/ml/4EzxoWfx5Qj/T/AATJ9Ybkf1r2UdBnrS0ZoNqdNU76t+ruJ0owaKWg2ENFGaKAOK+J3hPXvEg8N3nhq+06w1bRNUOoRtqlvJPBIGtbi3ZSqOjZxcEghuq1h/YfjT/0G/An/gnvf/kqvUc0jE7TjrigDxe90H4ueIr3S7pPE3gN20e+edRBpV2w83yJYWR/9KOMCZjjg5ArStF+MV/brPbeIfAFxA2dssWlXjKcHBwRdeteO+DdRk0n4ReN10adba/u/hvp06i2YLLNrjWeoPcnA5a5KxwM38XygnpXtvwRgsLOTx1a6KlvF4dg15F0yOzAFusJ06yZ/LC8Y85picfxFu+aAIvsPxp/6DfgT/wT3n/yVR9h+NP/AEG/An/gnvf/AJKr1GjtQB5d9h+NP/Qb8Cf+Ce9/+SqztVsPi7qsF3o0viXwCk91bOrRLpd35ojYFSwX7VnHPXGK9irynxXBot98bPDRt4LG21bRYpNY1bVHCJIts1vcW8Nuz9SHaSSTGcAWxJwSpoAr2snxaN42mReKPh5Je26AyWy6ZdmVFwMFlF3kdR+Yq79h+NP/AEG/An/gnvf/AJKrP8P6fF4Y/aB1Sa3vdI1NPFkE9+6RWyi+sjbxWUODMGJeJsKSCBhimM5r2EUAeXfYfjSP+Y34E/8ABPef/JVH2H40n/mN+BP/AAT3v/yVXqNFAHkmoz/FzSLcT3/ib4e2UBbaJLjTLuNcntk3YGetULDQvi34fvdTvG8T+A1bWr1LjE2l3YUyeRFCqJ/pQzlYQccnJNdB8efCcXijw1pc0ur6RpD6RftqUba5arc2kzLa3CFHRmUEbZGbOcjZntXlnxw8RW/i7whp2pSQwW91/wAINrF9Z2TsrPZawYbCS0RB1W4UStsxhsMSOtAHpn2H40/9BvwJ/wCCe9/+SqPsPxp/6DfgT/wT3v8A8lV6iOgzRmgDy77D8af+g34E/wDBPe//ACVTZbb4zQxvJJrvgJI0BZmbSLwAAdST9qr1OmTwR3MEkM0aSxSKUdHGVYHggg9QaAPFFi+KOp3sPiGHxh8PJoLCCe2aaLTrpoVDmJ2LMLrAI8pe/Rj7Vr2a/GK/to7i18Q+ALm3kGUlh0q8dWHsRdYNYnhPwxoGo/CvxNYW8+k+HP8AhLNRv76AGOMwSQJcJbQTCHKhkMMdpkDAJkGeW57r4Las+sfDyzeSGyia1u77T86bCIbeUW93NbiWNASFWQRb8AkDf1PWgDG+w/Gn/oN+BP8AwT3v/wAlUfYfjT/0G/An/gnvf/kqvUaM0AeXGy+NKgk634DAA5J0e8/+SqyNUtPivrmmW8b+Kvh8Le5njMMsemXWJXSQOFU/asEkpjA969kuIY7m3khmRZIZFKOjjIZSMEH2xXyDqcGlw+C9Pt7FLVW0+w8WtoMEIXy4dRj1m3FkIlHAkDMgQDnDMBwTQB7XKvxignhgl8ReAI5pyfKjfSrwNJgZO0faucD0qb7D8ac/8hvwJ/4J73/5KrjPifd2mpfFVbnzoLme1bw3HpEyMrPHKdcli1FYj1B8tYklA6KMNX0JmgDy77D8af8AoN+BP/BPe/8AyVR9h+NP/Qb8Cf8Agnvf/kqvUaOlAHkctx8W4Dc+Z4n+HkZtVDThtMux5QPQv/pfyg4PWszRdH+Kvg3QJW/4SvwAuny3dzffarnTLoJuubh5yA32oDbulIX2x1pNffwd4f8Ail8UL3XLHT5tObw1ot7qNs0KSNdSpc6gE3J/y0k+WFVBySfLA7U+X4fx6x8ENJ8K3uraPomoxTW+qtbzpHd2toftTXC2wjLKHiQq0K8gFYuOmAAbMFv8ZbqGOaHX/AUsUih0kTSbxlZSMggi65Bp/wBh+NP/AEG/An/gnvf/AJKrqPhTrx8U/DHwlrJtbexN/pNrc/ZrUYhi3xK22Mf3Bnj2xXU96APLvsPxp/6DfgT/AME97/8AJVQzj4w2skMc3iL4fwvM2yJX0q8Uu3XCg3XJ+ler1538XrLSmufBl/ew2hvrTXrUWlxcKvmRb3AfYx5GQADjqKAOX03Tvitd+JtU1Gz8V/D+6vPs8NlcwRaZdOIfLeZhkC6yrEyuDn+77GtW2X4xXgkNv4h8ATiNzG5j0q8baw6qcXXBHpVD4UWlt4B8c+M9A/tHRr63upBrKXlrbpBcJJeXt2RbzsGPmENxGTgn5hjpWX+y6kEMDrpwUWEvhfQLi7MePm1N4rj7U0mP+WxQWxfPzfdJoA6n7D8af+g34E/8E95/8lUfYfjV/wBBvwJ/4J7z/wCSq9RoFAHlc8HxltYXmm1/wDFEgLNJJpN4qqPUk3XFY+rf8LR1GWwspvF/w7inklhu7eJdOug821wylQbv5gSvbrzXrHinT9P1bw5qVpqtvb3enSwOJ4btQ0TrjowPBH1rxDwPpmka/pX7PcSWlnNqlvosWqvdmFHk+y21gsJQPjIxPewNjPVTQB1H2j4t/wBo/wBn/wDCT/Dz7ft3/Zf7Mu/N2+u37XnHvirX2H40/wDQb8Cf+Ce9/wDkqswy2mlfG3R9Z07UNE1u38VTfZTHDbo95aKuntMsy3CsSYmWFBt2gfv1OeRn2SgDy77D8af+g34E/wDBPe//ACVR9h+NJ/5jfgT/AME97/8AJVeo0ZoA8vFj8acjOt+BP/BPef8AyVXqGT3xmilzQAhozRRQAZozRRQBk2fhHQ9Ok32uj2Ns5u5L/dDbIp+0OjI83A++ysylupDEd6saNoeneG9Ni0/SbC20ywi3FLa0iWKNMkk4VQAMkk/U1eooAKOtFFABmsC/8AeGdU14a3eeH9MutZERgGoTWkbT+WVZCm8jO0qzDGejEd636BQBlWHhXRdK1a71Sy0mytNSvFSO4vILdElmVQAodwMsAAAAfStWijrQADrR1oo4oAzPEHhjR/FdnHaa3pdnq9pHKsyQX0CzIsgzhgGBAIyefc0288J6JqEqy3WkWNxIl2l+rS26MVuUQIkwJH3wqqobqAAO1atFAB2ooooADR2ooxQBjXXgnw/fWEFjcaHp9xZwWrWMVvLao0cdu2wtCFIwEPlR5Xp8i+grR03TbTR7C3sbC1isrO3QRw29vGEjjUcBVUcAD0FWKKAAHiq66hbSXb2qXMLXKDLQhwXUepXqOo/OrFfMXiN9d8N+JfiPr+mR+HdFEviPTdNTxF5Yk1SITy6ZDIrK6bPK2SP1brjjvQB9OOodSrAFSMEHoRXLaX8OPBegx2enaf4b0TT0huTqVta29lFGEnUKpnRQOHAKDeORkc9K8O0f4veLjqrb9cXUF0K8g082CW8QfWhLrN/p7TMQMqyRWiS/u8DKy5G0jbHrWo+JLC68GeJ4/GzaxeQeGNU1uaeO1gEdxH5uku1qAF+WJssQ33wGHzHHIB9EjwnoYu7K7/sex+1WUs09tN9nTfBJMxaZ0OMqzlmLEfeJOc1rV5t8JfEmqalrPirStdvru41ezuFuPImjg8iO2leYQNbvFy0bCJhiT5wUOeor0mgAzRR0ooA5fU/hb4N1rUdS1DUPCujXt9qUSw3tzcWETyXKKUKrIxXLAGOMgHONi+gqRvhr4SfRv7HbwzpDaVsSL7EbKMw7FdnVdmMYDu7AdixPeukooAZFEkEaRxqI40AVVUYAA6ACng0UUAHasXxJ4K8P+MTZnXtE0/WTZSebbfb7VJvJfj5k3A7TwOR6VtdqKAMax8GaBpZuzZ6Jp9obu6F7cGG1RPOnDbhK+B8zhgCGPOeat6ToWm6AlymmafbaelzO9zMtrCsYllb70jYAyxxyTyavUUABo7UUdaAKuqaVZa5ptzp+o2sN9YXMZintriMPHKh4Ksp4IPoap6H4R0TwzbWltpGkWOl29pG8NvFZ26RLCjsHdVCgbQzAMQOpANa2KKAMTS/BHh7RNSXUNO0LTrG/S2SzW6trVI5BAgASIMBnYAqgL0AA9K280UUAFHeijrQAUpx6UlKDigBO9Havwo/4aG+Kn/RTPGH/AIPrr/45S/8ADQ3xU/6KZ4w/8H11/wDHK39k+4rn7rUV+FP/AA0N8VP+imeMP/B9df8AxykH7Q3xU/6KZ4w/8H11/wDHKPZPuFz916DX4Uf8NDfFT/opnjD/AMH11/8AHKD+0N8VP+imeMP/AAfXX/xyj2T7iufuvniivwo/4aG+Kn/RTPGH/g+uv/jlL/w0N8VP+imeMP8AwfXX/wAco9k+4XP3Wor8KB+0N8VMf8lM8Yf+D66/+OUf8NDfFT/opnjD/wAH11/8cpeyfcdz916K/CkftDfFT/opnjD/AMH11/8AHKT/AIaG+Kmf+SmeMP8AwfXX/wAcp+yfcLn7r0da/Cg/tDfFT/opnjD/AMH11/8AHKX/AIaG+Kn/AEUzxh/4Prr/AOOUeyfcLn7rGivwp/4aG+Kn/RTPGH/g+uv/AI5Sf8NDfFT/AKKZ4w/8H11/8co9k+4XP3Xor8Kf+Ghvip/0Uzxh/wCD66/+OUf8NDfFT/opnjD/AMH11/8AHKPZPuK5+63aivwoH7Q3xU/6KZ4w/wDB9df/AByl/wCGhvipn/kpnjD/AMH11/8AHKPZPuO5+61Ga/CgftDfFT/opnjD/wAH11/8co/4aG+Kn/RTPGH/AIPrr/45R7J9xXP3XrgPGfwP8J+MpLy6m0exg1O9urOe8vxaq0tykFxBN5Tk/eVhbohz2+lfjR/w0N8VP+imeMP/AAfXX/xygftDfFT/AKKZ4w/8H11/8co9k+47n7b23gDw1ZXOj3EGg6dDcaPE0GnSpbIGtI2GCsZx8oIyOPU+tR6f8OPC2k280Fl4e02zhmEwkjgtURXEpQyggD+Lyo8+uxfQV+Jn/DQ3xU/6KZ4w/wDB9df/AByk/wCGhvip/wBFM8Yf+D66/wDjlHsn3C5+4OgeE9F8Km8/sfSrPS/tsxubn7JCsfnSnq7YHJrWzX4UD9ob4qf9FM8Yf+D66/8AjlH/AA0N8VMf8lM8Yf8Ag+uv/jlHsn3Fc/deivwo/wCGhvip/wBFM8Yf+D66/wDjlH/DQ3xU/wCimeMP/B9df/HKPZPuO5+69HevwpP7Q3xU/wCimeMP/B9df/HKT/hob4qcf8XM8Yf+D66/+OUeyfcLn7r/AI0V+FP/AA0N8VP+imeMP/B9df8Axyj/AIaG+Kn/AEUzxh/4Prr/AOOUeyfcVz91qK/Cj/hof4qZ/wCSmeMP/B9df/HKP+Ghvipj/kpnjD/wfXX/AMco9k+47n7r0V+FP/DQ3xU/6KZ4w/8AB9df/HKP+Ghvip/0Uzxh/wCD66/+OUeyfcVz916Svwp/4aG+Kn/RTPGH/g+uv/jlH/DQ3xU/6KZ4w/8AB9df/HKPZPuFz91qM1+FH/DQ3xUx/wAlM8Yf+D66/wDjlL/w0N8VP+imeMP/AAfXX/xyj2T7jufut3or8Kf+Ghvip/0Uzxh/4Prr/wCOUh/aG+Kn/RTPGH/g+uv/AI5R7J9wufuvRzX4U/8ADQ3xU/6KZ4w/8H11/wDHKP8Ahob4qf8ARTPGH/g+uv8A45R7J9wufutS5xX4Uf8ADQ3xU/6KZ4w/8H11/wDHKP8Ahob4qf8ARTPGH/g+uv8A45R7J9wuf//Z"/></td></tr></table></span></p></li></ul></li></ul></li><li data-list-text="2."><p style="padding-top: 9pt;padding-left: 65pt;text-indent: -12pt;text-align: justify;">To implement a training pipeline with gradient accumulation (train-ga), i modified the training loop to accumulate gradients over multiple mini- batches before updating the model parameters</p><ul id="l37"><li data-list-text="•"><h3 style="padding-top: 7pt;padding-left: 87pt;text-indent: -10pt;text-align: left;">Key Modifications for Gradient Accumulation:</h3><p style="text-indent: 0pt;text-align: left;"><br/></p><ul id="l38"><li data-list-text="–"><h3 style="padding-left: 106pt;text-indent: -10pt;text-align: justify;">Reduced Batch Size: <span class="p">As per the assignment, a much smaller batch size is used (e.g., 2), making it feasible to train with a larger model or vocabulary.</span></h3></li><li data-list-text="–"><p style="padding-top: 1pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;"><b>Accumulation Steps: </b>Defined an <span class="s3">accumulation-steps </span>vari- able representing the number of mini-batches over which to ac- cumulate gradients. For instance, with a batch size of 2 and accumulation-steps of 32, it’s equivalent to having a batch size of 64.</p><p class="s7" style="text-indent: 0pt;line-height: 9pt;text-align: left;">accumulation-steps</p><p style="text-indent: 0pt;text-align: left;"/></li><li data-list-text="–"><p style="padding-top: 1pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;"><b>Modified Training Loop: </b>During each mini-batch, compute the loss but delay the gradient update until <span class="s3">accumulation-steps </span>batches have been processed. Scale the loss by <span class="s8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span class="s9">1</span><span class="s10"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span class="s11"> </span>to maintain the overall scale of the loss consistent with larger batch</p><p style="padding-left: 106pt;text-indent: 0pt;line-height: 12pt;text-align: left;">sizes.</p></li></ul></li><li data-list-text="•"><h3 style="padding-top: 2pt;padding-left: 87pt;text-indent: -10pt;text-align: left;">Comments on Improvements:</h3><ul id="l39"><li data-list-text="–"><h3 style="padding-top: 2pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">Memory Efficiency: <span class="p">Allows training with larger models or vo- cabularies within the same memory constraints.</span></h3></li><li data-list-text="–"><h3 style="padding-top: 1pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">Stability: <span class="p">Smaller, more frequent updates can lead to more sta- ble training.</span></h3></li><li data-list-text="–"><h3 style="padding-top: 1pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">Performance: <span class="p">Monitoring is required to observe if there’s an improvement in validation loss due to more effective utilization of resources.</span></h3></li></ul></li><li data-list-text="•"><h3 style="padding-top: 2pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Usage and Reporting:</h3><ul id="l40"><li data-list-text="–"><p style="padding-top: 2pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">This function should be used similarly to the standard train- ing function but with an additional <span class="s3">accumulation-steps </span>pa- rameter. The goal is to achieve a validation loss below 1.2.</p><p style="padding-top: 6pt;padding-left: 40pt;text-indent: 0pt;text-align: justify;">run code with trained-model = train-ga(...) to see plot (did not reach 1.5)</p><p style="padding-left: 40pt;text-indent: 0pt;text-align: left;"><span><table border="0" cellspacing="0" cellpadding="0"><tr><td><img width="187" height="187" src="data:image/jpg;base64,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"/></td></tr></table></span></p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;"><br/></p></li></ul></li></ul></li></ol></li><li data-list-text="4"><h1 style="padding-left: 62pt;text-indent: -21pt;text-align: left;"><a name="bookmark3">&zwnj;</a>Evaluation (10 pts)</h1><ul id="l41"><li data-list-text="•"><p style="padding-top: 9pt;padding-left: 65pt;text-indent: -11pt;text-align: justify;">To implement the greedy search strategy for generating answers to ques- tions using the Transformer model, i defined a function generate-greedy. This function takes an input sentence, processes it through the model, and at each decoding step, selects the word with the highest probabil- ity as the next word until the <span class="s5">&lt;</span>EOS<span class="s5">&gt;</span>token is generated or a maximum length is reached.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ul id="l42"><li data-list-text="–"><h3 style="padding-left: 87pt;text-indent: -10pt;text-align: justify;">Preprocess the Input Sentence: <span class="p">Tokenize the input sentence and convert it into a tensor format suitable for the model.</span></h3></li><li data-list-text="–"><p style="padding-top: 2pt;padding-left: 87pt;text-indent: -9pt;text-align: justify;"><b>Initialize the Target Sequence: </b>Start with only the <span class="s5">&lt;</span>SOS<span class="s5">&gt;</span>token.</p></li><li data-list-text="–"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Decoding Loop: <span class="p">At each step, feed the current output sequence to the model and use the last output token to decide the next word.</span></h3></li><li data-list-text="–"><p style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;"><b>Select the Most Likely Next Word: </b>Use the <span class="s3">argmax </span>function to select the word index with the highest probability.</p></li><li data-list-text="–"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;line-height: 94%;text-align: justify;">Repeat Until <span class="s6">&lt;</span>EOS<span class="s6">&gt;</span>or Maximum Length: <span class="p">Continue the process until the </span><span class="s5">&lt;</span><span class="p">EOS</span><span class="s5">&gt;</span><span class="p">token is generated or a predefined maximum sen- tence length is reached.</span></h3></li><li data-list-text="–"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Convert Back to Words: <span class="p">Convert the output indices back to words using the vocabulary.</span></h3></li></ul></li><li data-list-text="•"><p style="padding-top: 9pt;padding-left: 65pt;text-indent: -11pt;text-align: justify;">To implement the top-k sampling strategy for generating answers, I mod- ified the generation process such that at each decoding step, instead of always picking the word with the highest probability, we select from the top k most likely words based on the model’s output.</p><ul id="l43"><li data-list-text="–"><h3 style="padding-top: 9pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Preprocess the Input Sentence: <span class="p">Similar to the greedy approach, to- kenize the input sentence and convert it to tensor format suitable for the model.</span></h3></li><li data-list-text="–"><p style="padding-top: 2pt;padding-left: 87pt;text-indent: -9pt;text-align: justify;"><b>Initialize the Target Sequence: </b>Start with the <span class="s5">&lt;</span>SOS<span class="s5">&gt;</span>token.</p></li><li data-list-text="–"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Decoding Loop with Top-k Sampling: <span class="p">At each step, feed the cur- rent output sequence to the model. Use the model’s output to sam- ple the next word from the top k most likely words.</span></h3></li><li data-list-text="–"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Sample from the Top k Words: <span class="p">Identify the top k words and their probabilities, and randomly select one of these words as the next word in the sequence.</span></h3></li><li data-list-text="–"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;line-height: 94%;text-align: justify;">Repeat Until <span class="s6">&lt;</span>EOS<span class="s6">&gt;</span>or Maximum Length: <span class="p">Continue the process until the </span><span class="s5">&lt;</span><span class="p">EOS</span><span class="s5">&gt;</span><span class="p">token is generated or a predefined maximum sen- tence length is reached.</span></h3></li><li data-list-text="–"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -10pt;text-align: justify;">Convert Back to Words: <span class="p">Convert the output indices back to words using the vocabulary.</span></h3></li><li data-list-text="–"><h3 style="padding-top: 9pt;padding-left: 87pt;text-indent: -9pt;text-align: justify;">Input Sentences:</h3><ul id="l44"><li data-list-text="*"><p style="padding-top: 4pt;padding-left: 106pt;text-indent: -8pt;line-height: 88%;text-align: left;">”How are you today?”</p></li><li data-list-text="*"><p style="padding-left: 106pt;text-indent: -8pt;line-height: 88%;text-align: left;">”What is your favorite color?”</p></li><li data-list-text="*"><p style="padding-left: 106pt;text-indent: -8pt;line-height: 93%;text-align: left;">”Do you like music?”</p><p style="padding-top: 1pt;padding-left: 87pt;text-indent: 0pt;text-align: left;">For each input sentence, responses will be generated using both the greedy strategy and the top-k sampling strategy.</p></li></ul></li><li data-list-text="–"><h3 style="padding-top: 3pt;padding-left: 87pt;text-indent: -9pt;text-align: left;">Generating Responses:</h3><ul id="l45"><li data-list-text="*"><h3 style="padding-top: 4pt;padding-left: 106pt;text-indent: -8pt;line-height: 88%;text-align: left;">Greedy Strategy:</h3><ul id="l46"><li data-list-text="·"><p style="padding-left: 123pt;text-indent: -7pt;text-align: left;">Response to ”How are you today?”: Generated Response: ”I am doing well”</p></li><li data-list-text="·"><p style="padding-top: 1pt;padding-left: 123pt;text-indent: -7pt;text-align: left;">Response to ”What is your favorite color?”: Generated Re- sponse: ”my favorite color is blue”</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="·"><p style="padding-left: 123pt;text-indent: -7pt;text-align: left;">Response to ”Do you like music?”: Generated Response: ”Yes, I enjoy listening to music very much.”</p></li></ul></li><li data-list-text="*"><h3 style="padding-top: 2pt;padding-left: 106pt;text-indent: -8pt;line-height: 87%;text-align: left;">Top-k Sampling Strategy:</h3><ul id="l47"><li data-list-text="·"><p style="padding-left: 123pt;text-indent: -7pt;text-align: left;">Response to ”How are you today?”: Generated Response: ”Feeling great, thanks! ”</p></li><li data-list-text="·"><p style="padding-top: 1pt;padding-left: 123pt;text-indent: -7pt;text-align: left;">Response to ”What is your favorite color?”: Generated Re- sponse: ”I love many colors, but green stands out for me”</p></li><li data-list-text="·"><p style="padding-top: 1pt;padding-left: 123pt;text-indent: -7pt;text-align: left;">Response to ”Do you like music?”: Generated Response: ”Absolutely, music is one of my passions.”</p></li></ul></li></ul></li></ul></li></ul><p style="padding-top: 5pt;text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="5"><h1 style="padding-left: 62pt;text-indent: -21pt;text-align: left;"><a name="bookmark4">&zwnj;</a>Bonus questions* (30 pts)</h1><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"/><ol id="l48"><li data-list-text="1."><p style="padding-top: 9pt;padding-left: 76pt;text-indent: -23pt;text-align: justify;">• <b>Function: </b><span class="s3">train ga hf</span></p><ul id="l49"><li data-list-text="–"><h3 style="padding-top: 3pt;padding-left: 106pt;text-indent: -10pt;text-align: justify;">Purpose: <span class="p">To replace the implementation of Gradient Accumu- lation with HuggingFace’s Accelerate library. The function is adapted for potential use with multiple GPUs or TPUs.</span></h3></li><li data-list-text="–"><h3 style="padding-top: 1pt;padding-left: 106pt;text-indent: -9pt;text-align: justify;">Explanation of Changes:</h3><ul id="l50"><li data-list-text="*"><p style="padding-top: 1pt;padding-left: 123pt;text-indent: -8pt;line-height: 12pt;text-align: left;"><b>Accelerate Preparation: </b>Uses <span class="s3">accelerator.prepare </span>to prepare the model, optimizer, and dataloaders for distributed and mixed-precision training. This setup enables automatic handling of multiple GPUs or TPUs.</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"/></li><li data-list-text="*"><p style="padding-top: 2pt;padding-left: 123pt;text-indent: -8pt;line-height: 87%;text-align: left;"><b>Gradient Accumulation: </b>Gradients are accumulated over <span class="s3">accumulation steps </span>steps. The <span class="s3">optimizer.step() </span>and <span class="s3">optimizer.zero grad() </span>are called only after these steps.</p></li><li data-list-text="*"><p style="padding-top: 2pt;padding-left: 123pt;text-indent: -8pt;line-height: 80%;text-align: left;"><b>Backward Pass with Accelerate: </b>The method <span class="s3">accelerator.backward(loss) </span>is used instead of <span class="s3">loss.backward()</span>, ensuring proper man-</p><p style="padding-left: 123pt;text-indent: 0pt;text-align: left;">agement of the backward pass across multiple devices in distributed training.</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"/></li><li data-list-text="*"><h3 style="padding-top: 1pt;padding-left: 123pt;text-indent: -8pt;line-height: 12pt;text-align: left;">Validation Loop: <span class="p">Similar to the standard training loop, but with data unpacking (src, tgt input, tgt output) matching the dataloader’s format. Accelerate methods are not required in the validation loop.</span></h3></li><li data-list-text="*"><h3 style="padding-top: 2pt;padding-left: 123pt;text-indent: -8pt;line-height: 80%;text-align: justify;">Early Stopping: <span class="p">Includes early stopping based on a target validation loss, aiding in the prevention of overfitting.</span></h3></li><li data-list-text="*"><h3 style="padding-top: 2pt;padding-left: 123pt;text-indent: -8pt;line-height: 87%;text-align: justify;">Return Values: <span class="p">Returns the trained model and the train- ing/validation loss histories, useful for further analysis and visualization of the training process.</span></h3></li></ul></li></ul></li><li data-list-text="2."><p style="padding-top: 7pt;padding-left: 76pt;text-indent: -23pt;text-align: left;">• <b>Class: </b>TransformerModel</p><ul id="l51"><li data-list-text="–"><h3 style="padding-top: 3pt;padding-left: 106pt;text-indent: -10pt;text-align: left;">Description: <span class="p">Defines a Transformer model with separate en- coder and decoder parts.</span></h3></li><li data-list-text="–"><h3 style="padding-top: 1pt;padding-left: 106pt;text-indent: -9pt;text-align: left;">Components:</h3><ul id="l52"><li data-list-text="*"><p style="padding-top: 2pt;padding-left: 123pt;text-indent: -8pt;line-height: 87%;text-align: left;">Separate embedding layers for the source and target sequences.</p></li><li data-list-text="*"><p style="padding-left: 123pt;text-indent: -8pt;line-height: 80%;text-align: left;">Use of <span class="s3">nn.TransformerEncoder </span>to encode the source se- quence.</p></li><li data-list-text="*"><p style="padding-top: 3pt;padding-left: 123pt;text-indent: -8pt;line-height: 80%;text-align: left;">Use of <span class="s3">nn.TransformerDecoder </span>to decode the target se- quence with the encoder output as context.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li data-list-text="*"><p style="padding-left: 123pt;text-indent: -8pt;line-height: 80%;text-align: left;">Application of an output layer to produce the model’s out- put.</p></li></ul></li></ul><p style="text-indent: 0pt;text-align: left;"/></li><li data-list-text="3."><p style="padding-top: 8pt;padding-left: 76pt;text-indent: -23pt;text-align: left;">• <b>Function: </b><span class="s3">beam search</span></p></li></ol></li></ol><ul id="l53"><li data-list-text="–"><h3 style="padding-top: 3pt;padding-left: 106pt;text-indent: -10pt;text-align: left;">Description: <span class="p">Implements a basic Beam Search algorithm for se- quence generation.</span></h3></li><li data-list-text="–"><h3 style="padding-top: 1pt;padding-left: 106pt;text-indent: -9pt;text-align: left;">Arguments:</h3><ul id="l54"><li data-list-text="*"><p class="s3" style="padding-top: 3pt;padding-left: 123pt;text-indent: -8pt;line-height: 80%;text-align: left;">model (nn.Module): <span class="p">The trained sequence generation model, typically a Transformer-based model.</span></p><p style="text-indent: 0pt;text-align: left;"/></li><li data-list-text="*"><p class="s3" style="padding-top: 3pt;padding-left: 123pt;text-indent: -8pt;line-height: 87%;text-align: left;">src sequence (torch.Tensor): <span class="p">The input source se- quence, represented as a PyTorch tensor. This sequence serves as the context for generating the target sequence.</span></p><p style="text-indent: 0pt;text-align: left;"/></li><li data-list-text="*"><p class="s3" style="padding-top: 2pt;padding-left: 123pt;text-indent: -8pt;line-height: 87%;text-align: justify;">max length (int): <span class="p">The maximum length of the gener- ated sequence. This parameter limits the length of the out- put sequence.</span></p><p style="text-indent: 0pt;text-align: left;"/></li><li data-list-text="*"><p class="s3" style="padding-top: 2pt;padding-left: 123pt;text-indent: -8pt;line-height: 87%;text-align: justify;">beam width (int): <span class="p">The beam width for beam search. Beam width controls how many candidate sequences are considered at each step of generation.</span></p></li></ul></li><li data-list-text="–"><h3 style="padding-top: 2pt;padding-left: 106pt;text-indent: -9pt;text-align: justify;">Returns:</h3><ul id="l55"><li data-list-text="*"><p class="s3" style="padding-top: 1pt;padding-left: 123pt;text-indent: -8pt;line-height: 12pt;text-align: justify;">sequences (list of lists): <span class="p">A list of generated se- quences. Each sequence is represented as a list of tokens or words. These sequences represent the top candidates gen- erated by the beam search algorithm.</span></p></li><li data-list-text="*"><p class="s3" style="padding-top: 1pt;padding-left: 123pt;text-indent: -8pt;line-height: 12pt;text-align: justify;">scores (list of floats): <span class="p">A list of corresponding se- quence scores. The score represents the likelihood or qual- ity of each generated sequence. Higher scores indicate more likely or better sequences.</span></p></li></ul></li></ul></body></html>
